{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = '标签'\n",
    "target = 0\n",
    "uid = '申请编号'\n",
    "columns = {}\n",
    "columns['no_fea'] = [uid, target, '申请时点']\n",
    "columns['01'] = [\n",
    "    '贷款类型',\n",
    "    '是否提供手机号',\n",
    "    '是否提供电话',\n",
    "    '手机号是否有效',\n",
    "    '是否提供email',\n",
    "    '申请人是否额外提供了文件2',\n",
    "    '申请人是否额外提供了文件3',\n",
    "    '申请人是否额外提供了文件4',\n",
    "    '申请人是否额外提供了文件5',\n",
    "    '申请人是否额外提供了文件6',\n",
    "    '申请人是否额外提供了文件7',\n",
    "    '申请人是否额外提供了文件8',\n",
    "    '申请人是否额外提供了文件9',\n",
    "    '是否有车',\n",
    "    '是否有房',\n",
    "    '地址是否一致标志1',\n",
    "    '地址是否一致标志2',\n",
    "    '地址是否一致标志3',\n",
    "    '地址是否一致标志4',\n",
    "    '地址是否一致标志5',\n",
    "    '地址是否一致标志6']\n",
    "columns['time'] = [\n",
    "    '申请周内日',\n",
    "    '申请时点',\n",
    "    '出生日期距申请日期天数']\n",
    "columns['_dt'] = [\n",
    "    '最近一次换手机号码距申请日天数',\n",
    "    '出生日期距申请日期天数',\n",
    "    '工作日期距申请日期天数',\n",
    "    '注册日期距申请日期天数',\n",
    "    '身份认证日期距申请日期天数']\n",
    "columns['money'] = [\n",
    "    '贷款年金',\n",
    "    '客户收入',\n",
    "    '商品价格',\n",
    "    '信用额度']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def calc_ks(y_test, y_proba):\n",
    "    s = pd.qcut(y_proba, 10, labels=False, duplicates='drop')\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, s)\n",
    "    KS = round(max(abs(fpr-tpr)) * 100, 1) # 横坐标倒序\n",
    "    return KS\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS\n",
    "\n",
    "def ks_score_lgb(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return 'KS', KS, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 63)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>申请编号</th>\n",
       "      <th>标签</th>\n",
       "      <th>贷款类型</th>\n",
       "      <th>信用额度</th>\n",
       "      <th>贷款年金</th>\n",
       "      <th>商品价格</th>\n",
       "      <th>陪同申请人</th>\n",
       "      <th>出生日期距申请日期天数</th>\n",
       "      <th>工作日期距申请日期天数</th>\n",
       "      <th>注册日期距申请日期天数</th>\n",
       "      <th>...</th>\n",
       "      <th>地址是否一致标志3</th>\n",
       "      <th>地址是否一致标志4</th>\n",
       "      <th>地址是否一致标志5</th>\n",
       "      <th>地址是否一致标志6</th>\n",
       "      <th>单位类型</th>\n",
       "      <th>社交圈违约信息2_2</th>\n",
       "      <th>社交圈违约信息2_1</th>\n",
       "      <th>社交圈违约信息1_2</th>\n",
       "      <th>社交圈违约信息1_1</th>\n",
       "      <th>最近一次换手机号码距申请日天数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>460190.889355</td>\n",
       "      <td>17463.042019</td>\n",
       "      <td>419951.511045</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-10107.0</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-5421.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424370.659603</td>\n",
       "      <td>15585.046388</td>\n",
       "      <td>384597.975692</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-13980.0</td>\n",
       "      <td>-1110.0</td>\n",
       "      <td>-3387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469330.587153</td>\n",
       "      <td>18837.558252</td>\n",
       "      <td>419951.511045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13331.0</td>\n",
       "      <td>-2246.0</td>\n",
       "      <td>-3870.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464188.353140</td>\n",
       "      <td>16754.587069</td>\n",
       "      <td>409850.500944</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-16540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>434196.988738</td>\n",
       "      <td>16165.009200</td>\n",
       "      <td>394698.985793</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-17919.0</td>\n",
       "      <td>-11037.0</td>\n",
       "      <td>-9350.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1049.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   申请编号  标签  贷款类型           信用额度          贷款年金           商品价格  陪同申请人  \\\n",
       "0     0   1     0  460190.889355  17463.042019  419951.511045    7.0   \n",
       "1     1   0     0  424370.659603  15585.046388  384597.975692    7.0   \n",
       "2     2   0     0  469330.587153  18837.558252  419951.511045    1.0   \n",
       "3     3   0     0  464188.353140  16754.587069  409850.500944    7.0   \n",
       "4     5   0     0  434196.988738  16165.009200  394698.985793    7.0   \n",
       "\n",
       "   出生日期距申请日期天数  工作日期距申请日期天数  注册日期距申请日期天数  ...  地址是否一致标志3  地址是否一致标志4  \\\n",
       "0     -10107.0       -342.0      -5421.0  ...          0          0   \n",
       "1     -13980.0      -1110.0      -3387.0  ...          0          0   \n",
       "2     -13331.0      -2246.0      -3870.0  ...          1          0   \n",
       "3     -16540.0          NaN       -970.0  ...          0          0   \n",
       "4     -17919.0     -11037.0      -9350.0  ...          1          1   \n",
       "\n",
       "   地址是否一致标志5  地址是否一致标志6  单位类型  社交圈违约信息2_2  社交圈违约信息2_1  社交圈违约信息1_2  社交圈违约信息1_1  \\\n",
       "0          0          0     5         0.0         0.0         0.0         0.0   \n",
       "1          0          1     5         0.0         0.0         0.0         0.0   \n",
       "2          0          0     5         0.0         0.0         0.0         0.0   \n",
       "3          0          0    57         1.0         0.0         1.0         0.0   \n",
       "4          0          1    53         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   最近一次换手机号码距申请日天数  \n",
       "0           -887.0  \n",
       "1           -271.0  \n",
       "2           -332.0  \n",
       "3           -204.0  \n",
       "4          -1049.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Ori '"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 62)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Load\n",
    "\n",
    "data_ori= pd.read_csv('./tmp/2_eda_outlier.csv', header=0, index_col=0)\n",
    "data_ori.shape\n",
    "data_ori.head()\n",
    "\n",
    "# Drop uid\n",
    "features_ori = data_ori.drop(uid, axis=1)\n",
    "''' Ori '''\n",
    "features_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00,  0.00000000e+00,  4.60190889e+05,  1.74630420e+04,\n",
       "        4.19951511e+05,  7.00000000e+00, -1.01070000e+04, -3.42000000e+02,\n",
       "       -5.42100000e+03, -3.29200000e+03,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  0.00000000e+00,  2.00000000e+00,  9.00000000e+00,\n",
       "        4.74687967e-01,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  6.35559864e-03,  7.25051997e-03,  3.40733007e-02,\n",
       "        2.89962794e-01,  2.74028223e-01,  2.27246211e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.37349581e+05,\n",
       "        1.00000000e+00,  2.00000000e+00,  3.00000000e+00,  1.00000000e+00,\n",
       "        2.23301980e-02,  5.84622526e+00,  6.00000000e+00,  1.00000000e+00,\n",
       "        5.96305847e-01,  7.61939951e-02,  1.15704946e-01,  1.10489524e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        5.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -8.87000000e+02])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Fill Null\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Fill Null\n",
    "imp =Imputer(missing_values=np.NaN, strategy=\"mean\", axis=0)\n",
    "# features = pd.DataFrame(imp.fit_transform(features_ori))\n",
    "# features.head()\n",
    "features = imp.fit_transform(features_ori)\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Training, Test '"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(98000, 61)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000, 61)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Train, Test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split\n",
    "X, X_test = train_test_split(features, test_size=0.3, random_state=123)\n",
    "y = X.pop(target)\n",
    "y_test = X_test.pop(target)\n",
    "\n",
    "''' Training, Test '''\n",
    "X.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  4.60190889e+05,  1.74630420e+04,  4.19951511e+05,\n",
       "        7.00000000e+00, -1.01070000e+04, -3.42000000e+02, -5.42100000e+03,\n",
       "       -3.29200000e+03,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  2.00000000e+00,  9.00000000e+00,  4.74687967e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        6.35559864e-03,  7.25051997e-03,  3.40733007e-02,  2.89962794e-01,\n",
       "        2.74028223e-01,  2.27246211e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  2.37349581e+05,  1.00000000e+00,\n",
       "        2.00000000e+00,  3.00000000e+00,  1.00000000e+00,  2.23301980e-02,\n",
       "        5.84622526e+00,  6.00000000e+00,  1.00000000e+00,  5.96305847e-01,\n",
       "        7.61939951e-02,  1.15704946e-01,  1.10489524e-01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  5.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -8.87000000e+02])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## k-fold\n",
    "\n",
    "# X = data\n",
    "# y = X.pop(0)\n",
    "# X.shape\n",
    "\n",
    "X = features[:, 1:]\n",
    "y = features[:, 0]\n",
    "X[0]\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## V1\n",
    "\n",
    "# Governing choices for search\n",
    "N_FOLDS = 5\n",
    "MAX_EVALS = 5\n",
    "params = {'num_boost_round' : 10000,\n",
    "          'num_leaves' : 2**5,\n",
    "              'feature_fraction' : 0.9,\n",
    "              'bagging_fraction' : 0.8,\n",
    "              'bagging_freq' : 5,\n",
    "              'random_state' : 123,\n",
    "              'is_unbalance' : True,\n",
    "              'early_stopping_rounds' : 100}\n",
    "\n",
    "gbm = lgb.LGBMClassifier(random_state=50)\n",
    "\n",
    "# Data set\n",
    "train = lgb.Dataset(X, y)\n",
    "\n",
    "# CV\n",
    "cv_results = lgb.cv(params, train, nfold = N_FOLDS, metrics = 'auc', verbose_eval = False, seed = 123)\n",
    "\n",
    "# Highest score\n",
    "best = cv_results['auc-mean'][-1]\n",
    "best\n",
    "\n",
    "# Standard deviation of best score\n",
    "best_std = cv_results['auc-stdv'][-1]\n",
    "best_std\n",
    "\n",
    "# Optimal number of esimators found in cv\n",
    "gbm.n_estimators = len(cv_results['auc-mean'])\n",
    "gbm.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## V2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits = 2\n",
    "x_score = []    # KSs\n",
    "cv_pred = []    # predictions\n",
    "\n",
    "params = {'num_boost_round' : 10000,\n",
    "          'num_leaves' : 2**5,\n",
    "          'feature_fraction' : 0.9,\n",
    "          'bagging_fraction' : 0.8,\n",
    "          'bagging_freq' : 5,\n",
    "          'random_state' : 123,\n",
    "          'is_unbalance' : True,\n",
    "          'early_stopping_rounds' : 100}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=123, shuffle=True)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    train_index.shape\n",
    "    # Get data\n",
    "    X_train, X_valid, y_train, y_valid = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    train_data = lgb.Dataset(X_train, y_train)\n",
    "    validation_data = lgb.Dataset(X_valid, y_valid)\n",
    "    # Train\n",
    "    clf = lgb.train(params, train_data, valid_sets=[validation_data],\n",
    "                    feval=ks_score_lgb, verbose_eval=1)\n",
    "    # Test\n",
    "    x_pred = clf.predict(X_valid, num_iteration=clf.best_iteration)\n",
    "    x_pred = [np.argmax(x) for x in x_pred]\n",
    "    x_score.append(ks_score_lgb(y_valid, x_pred)  # 计算f1值\n",
    "    y_test = clf.predict(X_test, num_iteration=clf.best_iteration)  # 预测\n",
    "    y_test = [np.argmax(x) for x in y_test]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* KS(0):0.3001 *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* KS(1):0.3068 *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* KS(0):0.1628 *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* KS(1):0.1485 *\n"
     ]
    }
   ],
   "source": [
    "base_models = [LGB, RF]\n",
    "base_models_ = [list() for x in base_models]\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=123)\n",
    "\n",
    "out_of_fold_predictions = np.zeros((X.shape[0], len(base_models)))\n",
    "for i, model in enumerate(base_models):\n",
    "    j = 0\n",
    "    for train_index, valid_index in kfold.split(X, y):\n",
    "        instance = clone(model)\n",
    "        base_models_[i].append(instance)\n",
    "        instance.fit(X[train_index],  y[train_index])\n",
    "        len(X[train_index])\n",
    "#         y_pred = instance.predict(X[valid_index])\n",
    "        y_pred = instance.predict_proba(X[valid_index])[:,1]\n",
    "        ks = ks_score(y[valid_index], y_pred)\n",
    "        print(f'* KS({j}):{ks} *')\n",
    "        out_of_fold_predictions[valid_index, i] = y_pred\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15064948, 0.1       ],\n",
       "       [0.31284796, 0.3       ],\n",
       "       [0.1214973 , 0.1       ],\n",
       "       [0.14398537, 0.        ],\n",
       "       [0.03966171, 0.2       ],\n",
       "       [0.12636723, 0.3       ],\n",
       "       [0.41769283, 0.5       ],\n",
       "       [0.17496637, 0.1       ],\n",
       "       [0.09707957, 0.2       ],\n",
       "       [0.24128142, 0.3       ]])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_fold_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3029"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model = LR\n",
    "meta_model_ = clone(meta_model)\n",
    "\n",
    "meta_model_.fit(out_of_fold_predictions, y)\n",
    "y_pred = meta_model_.predict_proba(out_of_fold_predictions)[:,1]\n",
    "ks_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features = np.column_stack ([\n",
    "    np.column_stack(\n",
    "        [model.predict_proba(X)[:,1] for model in base_models]\n",
    "    ).mean (axis=1)\n",
    "    for base_models in base_models_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3737"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3789"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5646"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5524"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for base_models in base_models_:\n",
    "    for model in base_models:\n",
    "        pred = model.predict_proba(X)[:,1]\n",
    "        ks_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "\n",
    "class StackingModels (BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=123)\n",
    "        \n",
    "        # Get results of basic models\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            print(f'*** Base Model: {model.__class__} ***')\n",
    "            j = 0\n",
    "            for train_index, valid_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index],  y[train_index])\n",
    "#                 y_pred = instance.predict(X[valid_index])\n",
    "                y_pred = instance.predict_proba(X[valid_index])[:,1]\n",
    "                ks = ks_score(y[valid_index], y_pred)\n",
    "                print(f'* KS({j}):{ks} *')\n",
    "                out_of_fold_predictions[valid_index, i] = y_pred\n",
    "                j += 1\n",
    "\n",
    "#         # 将交叉验证预测出的结果 和 训练集中的标签值进行训练\n",
    "#         self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "#         return self\n",
    "\n",
    "    # 从得到的新的特征  采用新的模型进行预测  并输出结果\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack ([\n",
    "            np.column_stack(\n",
    "#                 [model.predict(X) for model in base_models]\n",
    "                [model.predict_proba(X)[:,1] for model in base_models]\n",
    "            ).mean(axis=1)\n",
    "            for base_models in self.base_models_\n",
    "        ])\n",
    "#         return self.meta_model_.predict(meta_features)\n",
    "        return meta_features.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Base Model: <class 'lightgbm.sklearn.LGBMClassifier'> ***\n",
      "* KS(0):0.3204 *\n",
      "* KS(1):0.3107 *\n",
      "* KS(2):0.2957 *\n",
      "* KS(3):0.312 *\n",
      "* KS(4):0.3029 *\n",
      "*** Base Model: <class 'xgboost.sklearn.XGBClassifier'> ***\n",
      "* KS(0):0.2987 *\n",
      "* KS(1):0.2928 *\n",
      "* KS(2):0.2856 *\n",
      "* KS(3):0.2955 *\n",
      "* KS(4):0.2937 *\n",
      "*** Base Model: <class 'sklearn.ensemble.forest.RandomForestClassifier'> ***\n",
      "* KS(0):0.169 *\n",
      "* KS(1):0.1777 *\n",
      "* KS(2):0.1729 *\n",
      "* KS(3):0.1536 *\n",
      "* KS(4):0.1576 *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8961"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLF = StackingModels(base_models=[LGB, XGB, RF], meta_model=LR)\n",
    "CLF.fit(X, y)\n",
    "pred = CLF.predict(X)\n",
    "ks_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# {'n_estimators': [4,6],\n",
    "#                     'max_depth': [2,4]\n",
    "#                     }\n",
    "# RF = RandomSearchCV(RandomForestClassifier(),\n",
    "#                    , verbose=1)\n",
    "# RF.best_score_\n",
    "# RF.best_params_\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "\n",
    "# RF.fit(X, y)\n",
    "# pred = RF.predict_proba(X_test)\n",
    "# ks_score(y_test, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# params_xgb = {'max_depth' : 4,\n",
    "#               'subsample' : 0.8,\n",
    "#               'colsample_bytree' : 0.8}\n",
    "XGB = xgb.XGBClassifier()\n",
    "\n",
    "# XGB.fit(X, y)\n",
    "# pred = XGB.predict_proba(X_test)\n",
    "# ks_score(y_test, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# params_lgb = {'num_boost_round' : 10000,\n",
    "#           'num_leaves' : 2**5,\n",
    "#           'feature_fraction' : 0.9,\n",
    "#           'bagging_fraction' : 0.8,\n",
    "#           'bagging_freq' : 5,\n",
    "#           'random_state' : 123,\n",
    "#           'is_unbalance' : True,\n",
    "#           'early_stopping_rounds' : 100}\n",
    "LGB = lgb.LGBMClassifier()\n",
    "\n",
    "# LGB.fit(X, y)\n",
    "# pred = LGB.predict_proba(X_test)\n",
    "# ks_score(y_test, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "\n",
    "# LR.fit(X, y)\n",
    "# pred = LR.predict_proba(X_test)\n",
    "# ks_score(y_test, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Sample Balance\n",
    "#\n",
    "# data_ori = data_ori.drop(uid, axis=1)\n",
    "# ''' Ori '''\n",
    "# data_ori.shape\n",
    "# \n",
    "# data1 = data.loc[data[target]==1, :]\n",
    "# data0 = data.loc[data[target]==0, :]\n",
    "# frac = len(data1) / len(data0)\n",
    "# data0 = data0.sample(frac=frac, random_state=123)\n",
    "# data = pd.concat([data1, data0], axis=0)\n",
    "# ''' Balance '''\n",
    "# data[target].value_counts()\n",
    "\n",
    "# # Fill Null\n",
    "# data = data[data.columns.difference(columns['_dt'] + columns['money'])]\n",
    "# data.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************ Training ************************\n",
      "Training KS: 0.3946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1a2065e4e0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************ Test ************************\n",
      "Test KS: 0.3209\n"
     ]
    }
   ],
   "source": [
    "############### LGB Training\n",
    "\n",
    "def train_lgb(X, y):\n",
    "    # Data input\n",
    "    train = lgb.Dataset(X, y)\n",
    "    params = {'num_leaves' : 2**5,\n",
    "              'feature_fraction' : 0.9,\n",
    "              'bagging_fraction' : 0.8,\n",
    "              'bagging_freq' : 5,\n",
    "              'random_state' : 123,\n",
    "              'is_unbalance' : True,\n",
    "              'early_stopping_rounds' : 100\n",
    "              }\n",
    "    clf = lgb.train(params,\n",
    "                    train)\n",
    "    pred = clf.predict(X)\n",
    "    ks = ks_score(y, pred)\n",
    "    print(f'Training KS: {ks}')\n",
    "    return clf\n",
    "\n",
    "def test_lgb(clf, X):\n",
    "    pred = clf.predict(X, num_iterations=clf.best_iteration)\n",
    "    return pred\n",
    "\n",
    "\n",
    "### Training \n",
    "print('************************ Training ************************')\n",
    "\n",
    "gbm = train_lgb(X, y)\n",
    "gbm.save_model(f'./model/1_model_lgb.txt')\n",
    "\n",
    "print('************************ Test ************************')\n",
    "\n",
    "# print('* Training *')\n",
    "# train['score_lgb'] = test_lgb(gbm, X)\n",
    "# auc = calc_auc(train, 'score_lgb', target)\n",
    "# ks = calc_ks(train, 'score_lgb', target)\n",
    "# print(f'AUC:{auc}\\tKS:{ks}')\n",
    "\n",
    "X_test['score_lgb'] = test_lgb(gbm, X_test)\n",
    "ks = ks_score(y_test, X_test['score_lgb'])\n",
    "print(f'Test KS: {ks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ori '"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21511, 31)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21511, 32)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21511, 62)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(61, 2)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Test '"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21511"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Test\n",
    "\n",
    "def set_outlier(col):\n",
    "    if col < col_min:\n",
    "        col = col_min\n",
    "    elif col > col_max:\n",
    "        col = col_max\n",
    "    return col\n",
    "\n",
    "###################### Load \n",
    "\n",
    "''' Ori '''\n",
    "d1 = pd.read_csv('./data/A_Application.csv')\n",
    "d1.shape\n",
    "d2 = pd.read_csv('./data/A_Personas.csv')\n",
    "d2.shape\n",
    "d11 = pd.merge(d1, d2, how='inner', on='申请编号')\n",
    "d11.shape\n",
    "\n",
    "###################### Data Prepare \n",
    "\n",
    "X_test = d11.copy()\n",
    "uids = X_test.pop(uid)\n",
    "\n",
    "### 置空\n",
    "X_test.loc[X_test['孩子个数']==-1, '孩子个数'] = np.NaN\n",
    "# 距申请日期>0\n",
    "for col in columns['_dt']:\n",
    "    X_test.loc[X_test[col]>0, col] = np.NaN\n",
    "    \n",
    "### Outlier\n",
    "outliers = pd.read_csv('./tmp/0_outlier1.csv', index_col=0)\n",
    "\n",
    "for col in outliers.index:\n",
    "    col_min = outliers.loc[col, 'min']\n",
    "    col_max = outliers.loc[col, 'max']\n",
    "    X_test[col] = X_test[col].apply(set_outlier)\n",
    "    \n",
    "# Fill Null\n",
    "imp =Imputer(missing_values=np.NaN, strategy=\"mean\", axis=0)\n",
    "X_test = imp.fit_transform(X_test)\n",
    "\n",
    "''' Test '''\n",
    "len(X_test)\n",
    "len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>申请编号</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122687</td>\n",
       "      <td>0.082994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32425</td>\n",
       "      <td>0.102863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>0.096765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25019</td>\n",
       "      <td>0.175065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162532</td>\n",
       "      <td>0.187137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     申请编号         0\n",
       "0  122687  0.082994\n",
       "1   32425  0.102863\n",
       "2    2024  0.096765\n",
       "3   25019  0.175065\n",
       "4  162532  0.187137"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm_score(score):\n",
    "    if score < 0:\n",
    "        score = 0\n",
    "    elif score > 1:\n",
    "        score = 1\n",
    "    return score\n",
    "\n",
    "###################### Predict\n",
    "\n",
    "scores = CLF.predict(X_test)\n",
    "out = pd.concat([uids, pd.Series(scores)], axis=1)\n",
    "out[0] = out[0].apply(norm_score)\n",
    "out.head()\n",
    "\n",
    "out.to_csv('./model/predict.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
