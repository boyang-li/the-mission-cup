{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = '标签'\n",
    "target = 0\n",
    "uid = '申请编号'\n",
    "columns = {}\n",
    "columns['no_fea'] = [uid, target, '申请时点']\n",
    "columns['01'] = [\n",
    "    '贷款类型',\n",
    "    '是否提供手机号',\n",
    "    '是否提供电话',\n",
    "    '手机号是否有效',\n",
    "    '是否提供email',\n",
    "    '申请人是否额外提供了文件2',\n",
    "    '申请人是否额外提供了文件3',\n",
    "    '申请人是否额外提供了文件4',\n",
    "    '申请人是否额外提供了文件5',\n",
    "    '申请人是否额外提供了文件6',\n",
    "    '申请人是否额外提供了文件7',\n",
    "    '申请人是否额外提供了文件8',\n",
    "    '申请人是否额外提供了文件9',\n",
    "    '是否有车',\n",
    "    '是否有房',\n",
    "    '地址是否一致标志1',\n",
    "    '地址是否一致标志2',\n",
    "    '地址是否一致标志3',\n",
    "    '地址是否一致标志4',\n",
    "    '地址是否一致标志5',\n",
    "    '地址是否一致标志6']\n",
    "columns['time'] = [\n",
    "    '申请周内日',\n",
    "    '申请时点',\n",
    "    '出生日期距申请日期天数']\n",
    "columns['_dt'] = [\n",
    "    '最近一次换手机号码距申请日天数',\n",
    "    '出生日期距申请日期天数',\n",
    "    '工作日期距申请日期天数',\n",
    "    '注册日期距申请日期天数',\n",
    "    '身份认证日期距申请日期天数']\n",
    "columns['money'] = [\n",
    "    '贷款年金',\n",
    "    '客户收入',\n",
    "    '商品价格',\n",
    "    '信用额度']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def calc_ks(y_test, y_proba):\n",
    "    s = pd.qcut(y_proba, 10, labels=False, duplicates='drop')\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, s)\n",
    "    KS = round(max(abs(fpr-tpr)) * 100, 1) # 横坐标倒序\n",
    "    return KS\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS\n",
    "\n",
    "def ks_score_rf(estimator, y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS\n",
    "\n",
    "def ks_score_lgb(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return 'KS', KS, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 63)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>申请编号</th>\n",
       "      <th>标签</th>\n",
       "      <th>贷款类型</th>\n",
       "      <th>信用额度</th>\n",
       "      <th>贷款年金</th>\n",
       "      <th>商品价格</th>\n",
       "      <th>陪同申请人</th>\n",
       "      <th>出生日期距申请日期天数</th>\n",
       "      <th>工作日期距申请日期天数</th>\n",
       "      <th>注册日期距申请日期天数</th>\n",
       "      <th>...</th>\n",
       "      <th>地址是否一致标志3</th>\n",
       "      <th>地址是否一致标志4</th>\n",
       "      <th>地址是否一致标志5</th>\n",
       "      <th>地址是否一致标志6</th>\n",
       "      <th>单位类型</th>\n",
       "      <th>社交圈违约信息2_2</th>\n",
       "      <th>社交圈违约信息2_1</th>\n",
       "      <th>社交圈违约信息1_2</th>\n",
       "      <th>社交圈违约信息1_1</th>\n",
       "      <th>最近一次换手机号码距申请日天数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>460190.889355</td>\n",
       "      <td>17463.042019</td>\n",
       "      <td>419951.511045</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-10107.0</td>\n",
       "      <td>-342.0</td>\n",
       "      <td>-5421.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>424370.659603</td>\n",
       "      <td>15585.046388</td>\n",
       "      <td>384597.975692</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-13980.0</td>\n",
       "      <td>-1110.0</td>\n",
       "      <td>-3387.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>469330.587153</td>\n",
       "      <td>18837.558252</td>\n",
       "      <td>419951.511045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-13331.0</td>\n",
       "      <td>-2246.0</td>\n",
       "      <td>-3870.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-332.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>464188.353140</td>\n",
       "      <td>16754.587069</td>\n",
       "      <td>409850.500944</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-16540.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>434196.988738</td>\n",
       "      <td>16165.009200</td>\n",
       "      <td>394698.985793</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-17919.0</td>\n",
       "      <td>-11037.0</td>\n",
       "      <td>-9350.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1049.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   申请编号  标签  贷款类型           信用额度          贷款年金           商品价格  陪同申请人  \\\n",
       "0     0   1     0  460190.889355  17463.042019  419951.511045    7.0   \n",
       "1     1   0     0  424370.659603  15585.046388  384597.975692    7.0   \n",
       "2     2   0     0  469330.587153  18837.558252  419951.511045    1.0   \n",
       "3     3   0     0  464188.353140  16754.587069  409850.500944    7.0   \n",
       "4     5   0     0  434196.988738  16165.009200  394698.985793    7.0   \n",
       "\n",
       "   出生日期距申请日期天数  工作日期距申请日期天数  注册日期距申请日期天数  ...  地址是否一致标志3  地址是否一致标志4  \\\n",
       "0     -10107.0       -342.0      -5421.0  ...          0          0   \n",
       "1     -13980.0      -1110.0      -3387.0  ...          0          0   \n",
       "2     -13331.0      -2246.0      -3870.0  ...          1          0   \n",
       "3     -16540.0          NaN       -970.0  ...          0          0   \n",
       "4     -17919.0     -11037.0      -9350.0  ...          1          1   \n",
       "\n",
       "   地址是否一致标志5  地址是否一致标志6  单位类型  社交圈违约信息2_2  社交圈违约信息2_1  社交圈违约信息1_2  社交圈违约信息1_1  \\\n",
       "0          0          0     5         0.0         0.0         0.0         0.0   \n",
       "1          0          1     5         0.0         0.0         0.0         0.0   \n",
       "2          0          0     5         0.0         0.0         0.0         0.0   \n",
       "3          0          0    57         1.0         0.0         1.0         0.0   \n",
       "4          0          1    53         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   最近一次换手机号码距申请日天数  \n",
       "0           -887.0  \n",
       "1           -271.0  \n",
       "2           -332.0  \n",
       "3           -204.0  \n",
       "4          -1049.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Ori '"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 62)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Load\n",
    "\n",
    "data_ori= pd.read_csv('./tmp/2_eda_outlier.csv', header=0, index_col=0)\n",
    "data_ori.shape\n",
    "data_ori.head()\n",
    "\n",
    "# Drop uid\n",
    "features_ori = data_ori.drop(uid, axis=1)\n",
    "''' Ori '''\n",
    "features_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.00000000e+00,  0.00000000e+00,  4.60190889e+05,  1.74630420e+04,\n",
       "        4.19951511e+05,  7.00000000e+00, -1.01070000e+04, -3.42000000e+02,\n",
       "       -5.42100000e+03, -3.29200000e+03,  1.00000000e+00,  1.00000000e+00,\n",
       "        1.00000000e+00,  0.00000000e+00,  2.00000000e+00,  9.00000000e+00,\n",
       "        4.74687967e-01,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  6.35559864e-03,  7.25051997e-03,  3.40733007e-02,\n",
       "        2.89962794e-01,  2.74028223e-01,  2.27246211e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  2.37349581e+05,\n",
       "        1.00000000e+00,  2.00000000e+00,  3.00000000e+00,  1.00000000e+00,\n",
       "        2.23301980e-02,  5.84622526e+00,  6.00000000e+00,  1.00000000e+00,\n",
       "        5.96305847e-01,  7.61939951e-02,  1.15704946e-01,  1.10489524e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        5.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -8.87000000e+02])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Fill Null\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Fill Null\n",
    "imp =Imputer(missing_values=np.NaN, strategy=\"mean\", axis=0)\n",
    "# features = pd.DataFrame(imp.fit_transform(features_ori))\n",
    "# features.head()\n",
    "features = imp.fit_transform(features_ori)\n",
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Training, Test '"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(98000, 61)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(42000, 61)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Train, Test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split\n",
    "X, X_test = train_test_split(features, test_size=0.3, random_state=123)\n",
    "y = X.pop(target)\n",
    "y_test = X_test.pop(target)\n",
    "\n",
    "''' Training, Test '''\n",
    "X.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  4.60190889e+05,  1.74630420e+04,  4.19951511e+05,\n",
       "        7.00000000e+00, -1.01070000e+04, -3.42000000e+02, -5.42100000e+03,\n",
       "       -3.29200000e+03,  1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        0.00000000e+00,  2.00000000e+00,  9.00000000e+00,  4.74687967e-01,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        6.35559864e-03,  7.25051997e-03,  3.40733007e-02,  2.89962794e-01,\n",
       "        2.74028223e-01,  2.27246211e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  2.37349581e+05,  1.00000000e+00,\n",
       "        2.00000000e+00,  3.00000000e+00,  1.00000000e+00,  2.23301980e-02,\n",
       "        5.84622526e+00,  6.00000000e+00,  1.00000000e+00,  5.96305847e-01,\n",
       "        7.61939951e-02,  1.15704946e-01,  1.10489524e-01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  5.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -8.87000000e+02])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## k-fold\n",
    "\n",
    "# X = data\n",
    "# y = X.pop(0)\n",
    "# X.shape\n",
    "\n",
    "X = features[:, 1:]\n",
    "y = features[:, 0]\n",
    "X[0]\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## V1\n",
    "\n",
    "# Governing choices for search\n",
    "N_FOLDS = 5\n",
    "MAX_EVALS = 5\n",
    "params = {'num_boost_round' : 10000,\n",
    "          'num_leaves' : 2**5,\n",
    "              'feature_fraction' : 0.9,\n",
    "              'bagging_fraction' : 0.8,\n",
    "              'bagging_freq' : 5,\n",
    "              'random_state' : 123,\n",
    "              'is_unbalance' : True,\n",
    "              'early_stopping_rounds' : 100}\n",
    "\n",
    "gbm = lgb.LGBMClassifier(random_state=50)\n",
    "\n",
    "# Data set\n",
    "train = lgb.Dataset(X, y)\n",
    "\n",
    "# CV\n",
    "cv_results = lgb.cv(params, train, nfold = N_FOLDS, metrics = 'auc', verbose_eval = False, seed = 123)\n",
    "\n",
    "# Highest score\n",
    "best = cv_results['auc-mean'][-1]\n",
    "best\n",
    "\n",
    "# Standard deviation of best score\n",
    "best_std = cv_results['auc-stdv'][-1]\n",
    "best_std\n",
    "\n",
    "# Optimal number of esimators found in cv\n",
    "gbm.n_estimators = len(cv_results['auc-mean'])\n",
    "gbm.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## V2\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "n_splits = 2\n",
    "x_score = []    # KSs\n",
    "cv_pred = []    # predictions\n",
    "\n",
    "params = {'num_boost_round' : 10000,\n",
    "          'num_leaves' : 2**5,\n",
    "          'feature_fraction' : 0.9,\n",
    "          'bagging_fraction' : 0.8,\n",
    "          'bagging_freq' : 5,\n",
    "          'random_state' : 123,\n",
    "          'is_unbalance' : True,\n",
    "          'early_stopping_rounds' : 100}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=123, shuffle=True)\n",
    "for index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    train_index.shape\n",
    "    # Get data\n",
    "    X_train, X_valid, y_train, y_valid = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "    train_data = lgb.Dataset(X_train, y_train)\n",
    "    validation_data = lgb.Dataset(X_valid, y_valid)\n",
    "    # Train\n",
    "    clf = lgb.train(params, train_data, valid_sets=[validation_data],\n",
    "                    feval=ks_score_lgb, verbose_eval=1)\n",
    "    # Test\n",
    "    x_pred = clf.predict(X_valid, num_iteration=clf.best_iteration)\n",
    "    x_pred = [np.argmax(x) for x in x_pred]\n",
    "    x_score.append(ks_score_lgb(y_valid, x_pred)  # 计算f1值\n",
    "    y_test = clf.predict(X_test, num_iteration=clf.best_iteration)  # 预测\n",
    "    y_test = [np.argmax(x) for x in y_test]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* KS(0):0.3001 *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* KS(1):0.3068 *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* KS(0):0.1628 *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* KS(1):0.1485 *\n"
     ]
    }
   ],
   "source": [
    "base_models = [LGB, RF]\n",
    "base_models_ = [list() for x in base_models]\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=123)\n",
    "\n",
    "out_of_fold_predictions = np.zeros((X.shape[0], len(base_models)))\n",
    "for i, model in enumerate(base_models):\n",
    "    j = 0\n",
    "    for train_index, valid_index in kfold.split(X, y):\n",
    "        instance = clone(model)\n",
    "        base_models_[i].append(instance)\n",
    "        instance.fit(X[train_index],  y[train_index])\n",
    "        len(X[train_index])\n",
    "#         y_pred = instance.predict(X[valid_index])\n",
    "        y_pred = instance.predict_proba(X[valid_index])[:,1]\n",
    "        ks = ks_score(y[valid_index], y_pred)\n",
    "        print(f'* KS({j}):{ks} *')\n",
    "        out_of_fold_predictions[valid_index, i] = y_pred\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15064948, 0.1       ],\n",
       "       [0.31284796, 0.3       ],\n",
       "       [0.1214973 , 0.1       ],\n",
       "       [0.14398537, 0.        ],\n",
       "       [0.03966171, 0.2       ],\n",
       "       [0.12636723, 0.3       ],\n",
       "       [0.41769283, 0.5       ],\n",
       "       [0.17496637, 0.1       ],\n",
       "       [0.09707957, 0.2       ],\n",
       "       [0.24128142, 0.3       ]])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_fold_predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3029"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_model = LR\n",
    "meta_model_ = clone(meta_model)\n",
    "\n",
    "meta_model_.fit(out_of_fold_predictions, y)\n",
    "y_pred = meta_model_.predict_proba(out_of_fold_predictions)[:,1]\n",
    "ks_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_features = np.column_stack ([\n",
    "    np.column_stack(\n",
    "        [model.predict_proba(X)[:,1] for model in base_models]\n",
    "    ).mean (axis=1)\n",
    "    for base_models in base_models_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3737"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3789"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5646"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5524"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for base_models in base_models_:\n",
    "    for model in base_models:\n",
    "        pred = model.predict_proba(X)[:,1]\n",
    "        ks_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "\n",
    "class StackingModels (BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=123)\n",
    "        \n",
    "        # Get results of basic models\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            print(f'*** Base Model: {model.__class__} ***')\n",
    "            j = 0\n",
    "            for train_index, valid_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index],  y[train_index])\n",
    "#                 y_pred = instance.predict(X[valid_index])\n",
    "                y_pred = instance.predict_proba(X[valid_index])[:,1]\n",
    "                ks = ks_score(y[valid_index], y_pred)\n",
    "                print(f'* KS({j}):{ks} *')\n",
    "                out_of_fold_predictions[valid_index, i] = y_pred\n",
    "                j += 1\n",
    "\n",
    "#         # 将交叉验证预测出的结果 和 训练集中的标签值进行训练\n",
    "#         self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "#         return self\n",
    "\n",
    "    # 从得到的新的特征  采用新的模型进行预测  并输出结果\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack ([\n",
    "            np.column_stack(\n",
    "#                 [model.predict(X) for model in base_models]\n",
    "                [model.predict_proba(X)[:,1] for model in base_models]\n",
    "            ).mean(axis=1)\n",
    "            for base_models in self.base_models_\n",
    "        ])\n",
    "#         return self.meta_model_.predict(meta_features)\n",
    "        return meta_features.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Base Model: <class 'lightgbm.sklearn.LGBMClassifier'> ***\n",
      "* KS(0):0.3204 *\n",
      "* KS(1):0.3107 *\n",
      "* KS(2):0.2957 *\n",
      "* KS(3):0.312 *\n",
      "* KS(4):0.3029 *\n",
      "*** Base Model: <class 'xgboost.sklearn.XGBClassifier'> ***\n",
      "* KS(0):0.2987 *\n",
      "* KS(1):0.2928 *\n",
      "* KS(2):0.2856 *\n",
      "* KS(3):0.2955 *\n",
      "* KS(4):0.2937 *\n",
      "*** Base Model: <class 'sklearn.ensemble.forest.RandomForestClassifier'> ***\n",
      "* KS(0):0.169 *\n",
      "* KS(1):0.1777 *\n",
      "* KS(2):0.1729 *\n",
      "* KS(3):0.1536 *\n",
      "* KS(4):0.1576 *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8961"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = joblib.load('./model/base_rf.m')\n",
    "\n",
    "CLF = StackingModels(base_models=[LGB, XGB, RF], meta_model=LR)\n",
    "CLF.fit(X, y)\n",
    "pred = CLF.predict(X)\n",
    "ks_score(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Grid Search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "param_fixed_search = {\n",
    "    'n_iter' : 2,\n",
    "    'cv' : 2, \n",
    "    'scoring' : 'roc_auc', \n",
    "    'n_jobs' : -1, \n",
    "    'random_state' : 123, \n",
    "    'verbose' : 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9842"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   12.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=123, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=2, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': range(50, 100, 10), 'max_features': ['sqrt', 'log2'], 'max_depth': range(3, 10), 'min_samples_leaf': range(50, 100, 10), 'criterion': ['gini', 'entropy'], 'oob_score': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.685744518607443"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['./model/base_rf.m']"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Test '"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=9, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=90, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=None,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.314"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_dist = {\n",
    "#     'n_estimators' : range(100,500,50),\n",
    "    'n_estimators' : range(50,100,10),\n",
    "    'max_features' : ['sqrt', 'log2'],\n",
    "    'max_depth' : range(2, 10),\n",
    "    'min_samples_split' : range(50, 100, 10),\n",
    "    'min_samples_leaf' : range(50, 100, 10),\n",
    "    'criterion' : ['gini', 'entropy']}\n",
    "param_fixed_model = {\n",
    "    'oob_score' : True,\n",
    "    'random_state':123,\n",
    "    'verbose':0}\n",
    "\n",
    "''' Baseline '''\n",
    "rf = RandomForestClassifier(**param_fixed_model)\n",
    "rf.fit(X, y)\n",
    "pred = rf.predict_proba(X)\n",
    "ks_score(y, pred[:,1])\n",
    "\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(RandomForestClassifier(**param_fixed_model), param_dist, **param_fixed_search)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "# Dump\n",
    "RF = RandomForestClassifier(**best_params)\n",
    "joblib.dump(RF, './model/base_rf.m')\n",
    "\n",
    "''' Test '''\n",
    "rf = clone(RF)\n",
    "rf.fit(X, y)\n",
    "pred = rf.predict_proba(X)\n",
    "ks_score(y, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-457-6eab51397cd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/base_rf.m'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# rf.fit(X, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mks_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AppPkg/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \"\"\"\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AppPkg/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "rf1 = joblib.load('./model/base_rf.m')\n",
    "# rf.fit(X, y)\n",
    "pred = rf1.predict_proba(X)\n",
    "ks_score(y, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators' : range(50,100,10),\n",
    "    'subsample' : np.linspace(0.7,0.9,2)\n",
    "    'max_depth':range(2,15,1),\n",
    "    'eta' : np.linspace(0.1,0.5,2)\n",
    "    'learning_rate':np.linspace(0.01,2,20),\n",
    "    \n",
    "    'colsample_bytree':np.linspace(0.5,0.98,10),\n",
    "    'min_child_weight':range(1,9,1)}\n",
    "XGB = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth' : range(3,10),\n",
    "    'min_samples_leaf' : range(50, 100, 10),\n",
    "    \n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'oob_score' : [True, False]}\n",
    "param_fixed = {\n",
    "    'random_state':123,\n",
    "    'verbose':0}\n",
    "\n",
    "''' Baseline '''\n",
    "rf = RandomForestClassifier(**param_fixed)\n",
    "rf.fit(X, y)\n",
    "pred = rf.predict_proba(X)\n",
    "ks_score(y, pred[:,1])\n",
    "\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(RandomForestClassifier(**param_fixed), param_dist, n_iter=2, cv=2, \n",
    "                          scoring='roc_auc', n_jobs=-1, random_state=123, verbose=1)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "# Dump\n",
    "RF = RandomForestClassifier(**best_params)\n",
    "joblib.dump(RF, './model/base_rf.m')\n",
    "\n",
    "''' Test '''\n",
    "rf = clone(RF)\n",
    "rf.fit(X, y)\n",
    "pred = rf.predict_proba(X)\n",
    "ks_score(y, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-458-4e6b8a8d0ca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspace_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp,space_eval,rand,Trials,partial,STATUS_OK\n",
    "\n",
    "# 定义一个目标函数,接受一个变量,计算后返回一个函数的损失值，\n",
    "def GBM(argsDict):\n",
    "    max_depth = argsDict[\"max_depth\"] + 5\n",
    "    n_estimators = argsDict['n_estimators'] * 5 + 50\n",
    "    learning_rate = argsDict[\"learning_rate\"] * 0.02 + 0.05\n",
    "    subsample = argsDict[\"subsample\"] * 0.1 + 0.7\n",
    "    min_child_weight = argsDict[\"min_child_weight\"]+1\n",
    "    global attr_train,label_train\n",
    "\n",
    "    gbm = xgb.XGBClassifier(nthread=4,    #进程数\n",
    "                            max_depth=max_depth,  #最大深度\n",
    "                            n_estimators=n_estimators,   #树的数量\n",
    "                            learning_rate=learning_rate, #学习率\n",
    "                            subsample=subsample,      #采样数\n",
    "                            min_child_weight=min_child_weight,   #孩子数\n",
    "                            max_delta_step = 10,  #10步不降则停止\n",
    "                            objective=\"binary:logistic\")\n",
    "\n",
    "    metric = cross_val_score(gbm,attr_train,label_train,cv=5,scoring=\"roc_auc\").mean()\n",
    "    print(metric)\n",
    "    return metric\n",
    "\n",
    "# 定义参数的搜索空间\n",
    "\n",
    "space = {\"max_depth\":hp.randint(\"max_depth\",15),\n",
    "         \"n_estimators\":hp.randint(\"n_estimators\",10),  #[0,1,2,3,4,5] -> [50,]\n",
    "         \"learning_rate\":hp.randint(\"learning_rate\",6),  #[0,1,2,3,4,5] -> 0.05,0.06\n",
    "         \"subsample\":hp.randint(\"subsample\",4),#[0,1,2,3] -> [0.7,0.8,0.9,1.0]\n",
    "         \"min_child_weight\":hp.randint(\"min_child_weight\",5), #\n",
    "        }\n",
    "algo = partial(tpe.suggest, n_startup_jobs=1)  # 定义随机搜索算法。搜索算法本身也有内置的参数决定如何去优化目标函数\n",
    "best = fmin(GBM, space, algo=algo, max_evals=4)  # 对定义的参数范围，调用搜索算法，对模型进行搜索\n",
    "\n",
    "print(best)\n",
    "print(GBM(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# params_lgb = {'num_boost_round' : 10000,\n",
    "#           'num_leaves' : 2**5,\n",
    "#           'feature_fraction' : 0.9,\n",
    "#           'bagging_fraction' : 0.8,\n",
    "#           'bagging_freq' : 5,\n",
    "#           'random_state' : 123,\n",
    "#           'is_unbalance' : True,\n",
    "#           'early_stopping_rounds' : 100}\n",
    "LGB = lgb.LGBMClassifier()\n",
    "\n",
    "# LGB.fit(X, y)\n",
    "# pred = LGB.predict_proba(X_test)\n",
    "# ks_score(y_test, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "\n",
    "# LR.fit(X, y)\n",
    "# pred = LR.predict_proba(X_test)\n",
    "# ks_score(y_test, pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Sample Balance\n",
    "#\n",
    "# data_ori = data_ori.drop(uid, axis=1)\n",
    "# ''' Ori '''\n",
    "# data_ori.shape\n",
    "# \n",
    "# data1 = data.loc[data[target]==1, :]\n",
    "# data0 = data.loc[data[target]==0, :]\n",
    "# frac = len(data1) / len(data0)\n",
    "# data0 = data0.sample(frac=frac, random_state=123)\n",
    "# data = pd.concat([data1, data0], axis=0)\n",
    "# ''' Balance '''\n",
    "# data[target].value_counts()\n",
    "\n",
    "# # Fill Null\n",
    "# data = data[data.columns.difference(columns['_dt'] + columns['money'])]\n",
    "# data.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************ Training ************************\n",
      "Training KS: 0.3946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1a2065e4e0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************ Test ************************\n",
      "Test KS: 0.3209\n"
     ]
    }
   ],
   "source": [
    "############### LGB Training\n",
    "\n",
    "def train_lgb(X, y):\n",
    "    # Data input\n",
    "    train = lgb.Dataset(X, y)\n",
    "    params = {'num_leaves' : 2**5,\n",
    "              'feature_fraction' : 0.9,\n",
    "              'bagging_fraction' : 0.8,\n",
    "              'bagging_freq' : 5,\n",
    "              'random_state' : 123,\n",
    "              'is_unbalance' : True,\n",
    "              'early_stopping_rounds' : 100\n",
    "              }\n",
    "    clf = lgb.train(params,\n",
    "                    train)\n",
    "    pred = clf.predict(X)\n",
    "    ks = ks_score(y, pred)\n",
    "    print(f'Training KS: {ks}')\n",
    "    return clf\n",
    "\n",
    "def test_lgb(clf, X):\n",
    "    pred = clf.predict(X, num_iterations=clf.best_iteration)\n",
    "    return pred\n",
    "\n",
    "\n",
    "### Training \n",
    "print('************************ Training ************************')\n",
    "\n",
    "gbm = train_lgb(X, y)\n",
    "gbm.save_model(f'./model/1_model_lgb.txt')\n",
    "\n",
    "print('************************ Test ************************')\n",
    "\n",
    "# print('* Training *')\n",
    "# train['score_lgb'] = test_lgb(gbm, X)\n",
    "# auc = calc_auc(train, 'score_lgb', target)\n",
    "# ks = calc_ks(train, 'score_lgb', target)\n",
    "# print(f'AUC:{auc}\\tKS:{ks}')\n",
    "\n",
    "X_test['score_lgb'] = test_lgb(gbm, X_test)\n",
    "ks = ks_score(y_test, X_test['score_lgb'])\n",
    "print(f'Test KS: {ks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ori '"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21511, 31)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21511, 32)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21511, 62)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(61, 2)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Test '"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "21511"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############### Test\n",
    "\n",
    "def set_outlier(col):\n",
    "    if col < col_min:\n",
    "        col = col_min\n",
    "    elif col > col_max:\n",
    "        col = col_max\n",
    "    return col\n",
    "\n",
    "###################### Load \n",
    "\n",
    "''' Ori '''\n",
    "d1 = pd.read_csv('./data/A_Application.csv')\n",
    "d1.shape\n",
    "d2 = pd.read_csv('./data/A_Personas.csv')\n",
    "d2.shape\n",
    "d11 = pd.merge(d1, d2, how='inner', on='申请编号')\n",
    "d11.shape\n",
    "\n",
    "###################### Data Prepare \n",
    "\n",
    "X_test = d11.copy()\n",
    "uids = X_test.pop(uid)\n",
    "\n",
    "### 置空\n",
    "X_test.loc[X_test['孩子个数']==-1, '孩子个数'] = np.NaN\n",
    "# 距申请日期>0\n",
    "for col in columns['_dt']:\n",
    "    X_test.loc[X_test[col]>0, col] = np.NaN\n",
    "    \n",
    "### Outlier\n",
    "outliers = pd.read_csv('./tmp/0_outlier1.csv', index_col=0)\n",
    "\n",
    "for col in outliers.index:\n",
    "    col_min = outliers.loc[col, 'min']\n",
    "    col_max = outliers.loc[col, 'max']\n",
    "    X_test[col] = X_test[col].apply(set_outlier)\n",
    "    \n",
    "# Fill Null\n",
    "imp =Imputer(missing_values=np.NaN, strategy=\"mean\", axis=0)\n",
    "X_test = imp.fit_transform(X_test)\n",
    "\n",
    "''' Test '''\n",
    "len(X_test)\n",
    "len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>申请编号</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122687</td>\n",
       "      <td>0.082994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32425</td>\n",
       "      <td>0.102863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>0.096765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25019</td>\n",
       "      <td>0.175065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162532</td>\n",
       "      <td>0.187137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     申请编号         0\n",
       "0  122687  0.082994\n",
       "1   32425  0.102863\n",
       "2    2024  0.096765\n",
       "3   25019  0.175065\n",
       "4  162532  0.187137"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm_score(score):\n",
    "    if score < 0:\n",
    "        score = 0\n",
    "    elif score > 1:\n",
    "        score = 1\n",
    "    return score\n",
    "\n",
    "###################### Predict\n",
    "\n",
    "scores = CLF.predict(X_test)\n",
    "out = pd.concat([uids, pd.Series(scores)], axis=1)\n",
    "out[0] = out[0].apply(norm_score)\n",
    "out.head()\n",
    "\n",
    "out.to_csv('./model/predict.csv', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
