{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Meng/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats as spstats\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, PolynomialFeatures, StandardScaler, scale as skscale\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Load '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Merge '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' drop id'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Split '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 811)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' *** With na *** '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Load '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Merge '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Split '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 811)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Load\n",
    "\n",
    "# For kfold\n",
    "n_folds = 5\n",
    "\n",
    "''' Load '''\n",
    "Xid = pd.read_csv('./tmp/train_d1234_nona.csv', header=0, index_col=0)#.head(10000)\n",
    "Xid.shape\n",
    "\n",
    "yid = pd.read_csv('./data/train_label.csv', header=0, index_col=0)#.head(10000)\n",
    "yid.shape\n",
    "\n",
    "''' Merge '''\n",
    "# Merge\n",
    "xy = pd.merge(Xid, yid, on=uid, how='inner')\n",
    "\n",
    "# ''' Filter Bins ''' \n",
    "# uids = pd.read_csv('./tmp/train_uid0.csv', header=0, index_col=0)\n",
    "# uids.columns = [uid]\n",
    "# xy = pd.merge(uids, xy, on=uid, how='left')\n",
    "# xy.shape\n",
    "\n",
    "''' drop id'''\n",
    "xy.drop(uid, axis=1, inplace=True)\n",
    "xy.shape\n",
    "\n",
    "''' Split '''\n",
    "# X, y\n",
    "X = xy.copy()\n",
    "y = X.pop(target)\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "''' *** With na *** '''\n",
    "\n",
    "''' Load '''\n",
    "Xid1 = pd.read_csv('./tmp/train_d1234_na.csv', header=0, index_col=0)#.head(10000)\n",
    "Xid1.shape\n",
    "\n",
    "''' Merge '''\n",
    "xy1 = pd.merge(Xid1, yid, on=uid, how='inner')\n",
    "xy1.drop(uid, axis=1, inplace=True)\n",
    "xy1.shape\n",
    "\n",
    "''' Split '''\n",
    "# X, y\n",
    "X1 = xy1.copy()\n",
    "y1 = X1.pop(target)\n",
    "X1.shape\n",
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "param_fixed_rf = {\n",
    "    'n_jobs' : -1,\n",
    "    'oob_score' : True,\n",
    "    'random_state':123,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_fixed_xgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'seed' : 123,\n",
    "    'silent' : 1,\n",
    "    'verbose_eval':0\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_fixed_lgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'metric' : 'auc',\n",
    "    'random_state' : 123,\n",
    "    'bagging_seed':123,\n",
    "    'feature_fraction_seed':123,\n",
    "    'verbose_eval' : 0\n",
    "}\n",
    "\n",
    "# LR\n",
    "param_fixed_lr = {\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 123,\n",
    "    'verbose' : 0     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Load Features '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr:54\n",
      "rf:198\n",
      "xgb:811\n",
      "lgb:811\n",
      "lgbna:811\n",
      "*** Base Model: <class 'lightgbm.sklearn.LGBMClassifier'>, Features: 811 ***\n",
      "0.3688\n",
      "0.3701\n",
      "0.3493\n",
      "0.364\n",
      "0.3573\n",
      "*** Base Model: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, Features: 198 ***\n",
      "0.3182\n",
      "0.3103\n",
      "0.3138\n",
      "0.313\n",
      "0.3123\n",
      "*** Base Model: <class 'xgboost.sklearn.XGBClassifier'>, Features: 811 ***\n",
      "0.3636\n",
      "0.3598\n",
      "0.3417\n",
      "0.3618\n",
      "0.3502\n",
      "*** Base Model: <class 'sklearn.linear_model.logistic.LogisticRegression'>, Features: 54 ***\n",
      "0.256\n",
      "0.2493\n",
      "0.2527\n",
      "0.249\n",
      "0.2467\n",
      "*** Base Model Na: <class 'lightgbm.sklearn.LGBMClassifier'>, Features: 811 ***\n",
      "0.3693\n",
      "0.3667\n",
      "0.3531\n",
      "0.3647\n",
      "0.3587\n",
      "*** Meta Model: <class 'sklearn.linear_model.logistic.LogisticRegression'>, Features: 15 ***\n",
      "0.372\n",
      "0.3727\n",
      "0.3558\n",
      "0.371\n",
      "0.3611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingModels(base_feats=[{'25岁以下', '25岁到30岁', '30岁到40岁', '40岁到50岁', '50岁以上',\n",
       "                            'is_odue30sumsumsum', 'is_odue60sumsumsum',\n",
       "                            'is_odue90sumsumsum', 'is_oduesumsumsum',\n",
       "                            'time_diffmeanmaxmax', 'time_diffmeanmeanmean',\n",
       "                            '一月内换过手机号', '产品类型_0mean_x', '产品类型_0mean_y',\n",
       "                            '产品类型_0sum_x', '产品类型_0sum_y', '产品类型_1mean_x',\n",
       "                            '产品类型_1mean_y', '产品类型_1sum_x', '产品类型_1sum_y',\n",
       "                            '产品类型_2mean_x', '产品类型_...\n",
       "                                              random_state=123, reg_alpha=0.0,\n",
       "                                              reg_lambda=0.0, silent=True,\n",
       "                                              subsample=0.8, ...)],\n",
       "               if_feats_select=True,\n",
       "               meta_model=LogisticRegression(C=0.1, class_weight=1, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='warn',\n",
       "                                             n_jobs=-1, penalty='l2',\n",
       "                                             random_state=123, solver='lbfgs',\n",
       "                                             tol=0.0001, verbose=0,\n",
       "                                             warm_start=False),\n",
       "               n_folds=5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StackingModels (BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, base_models_na, base_feats, meta_model, if_feats_select, n_folds = n_folds):\n",
    "        self.base_models = base_models\n",
    "        self.base_models_na = base_models_na\n",
    "        self.meta_model = meta_model\n",
    "        self.if_feats_select = if_feats_select\n",
    "        # base_feats\n",
    "        self.base_feats = []\n",
    "        if self.if_feats_select == True:\n",
    "            self.base_feats = base_feats\n",
    "        self.n_folds = n_folds\n",
    "        self.meta_X = []\n",
    "\n",
    "    def fit(self, X_ttl, Xna_ttl, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.base_models_na_ = [list() for x in self.base_models_na]\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=123)\n",
    "        \n",
    "        # Get results of basic models\n",
    "        out_of_fold_predictions = np.zeros((X_ttl.shape[0], len(self.base_models)+len(self.base_models_na)))\n",
    "        \n",
    "        # Feature without Null\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            ### If select features\n",
    "            if self.if_feats_select == True:\n",
    "                X = X_ttl[self.base_feats[i]]\n",
    "            else:\n",
    "                X = X_ttl\n",
    "            l = len(X.columns) # Feature count\n",
    "            print(f'*** Base Model: {model.__class__}, Features: {l} ***')\n",
    "            \n",
    "            j = 0\n",
    "            # Train\n",
    "            for train_index, valid_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X.iloc[train_index],  y.iloc[train_index])\n",
    "                y_pred = instance.predict_proba(X.iloc[valid_index])[:,1]\n",
    "                ks = ks_score(y.iloc[valid_index], y_pred)\n",
    "                print(ks)\n",
    "                out_of_fold_predictions[valid_index, i] = y_pred\n",
    "                j += 1\n",
    "        # Feature with Null\n",
    "        for k, model in enumerate(self.base_models_na):\n",
    "            i += 1\n",
    "            ### If select features\n",
    "            if self.if_feats_select == True:\n",
    "                X = Xna_ttl[self.base_feats[i]]\n",
    "            else:\n",
    "                X = Xna_ttl\n",
    "            l = len(X.columns) # Feature count\n",
    "            print(f'*** Base Model Na: {model.__class__}, Features: {l} ***')\n",
    "            \n",
    "            j = 0\n",
    "            # Train\n",
    "            for train_index, valid_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_na_[k].append(instance)\n",
    "                instance.fit(X.iloc[train_index],  y.iloc[train_index])\n",
    "                y_pred = instance.predict_proba(X.iloc[valid_index])[:,1]\n",
    "                ks = ks_score(y.iloc[valid_index], y_pred)\n",
    "                print(ks)\n",
    "                out_of_fold_predictions[valid_index, i] = y_pred\n",
    "                j += 1        \n",
    "\n",
    "        # META\n",
    "        self.meta_X = out_of_fold_predictions\n",
    "        # Polynomial\n",
    "        poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "        X = poly.fit_transform(out_of_fold_predictions)\n",
    "        l = len(X[0]) # Feature Count\n",
    "        print(f'*** Meta Model: {self.meta_model.__class__}, Features: {l} ***')\n",
    "        j = 0\n",
    "        self.meta_models_ = []\n",
    "        for train_index, valid_index in kfold.split(X, y):\n",
    "            instance = clone(self.meta_model)\n",
    "            self.meta_models_.append(instance)\n",
    "            instance.fit(X[train_index],  y[train_index])\n",
    "            y_pred = instance.predict_proba(X[valid_index])[:,1]\n",
    "            ks = ks_score(y[valid_index], y_pred)\n",
    "            print(ks)\n",
    "            j += 1\n",
    "        return self\n",
    "\n",
    "    # Prediect\n",
    "    def predict(self, X_ttl, Xna_ttl, if_meta=True):\n",
    "        \n",
    "        # Features for Meta Model       \n",
    "        meta_features = pd.DataFrame()\n",
    "        for i, models_kfold in enumerate(self.base_models_):\n",
    "            # If select features\n",
    "            if self.if_feats_select == True:\n",
    "                X = X_ttl[self.base_feats[i]]\n",
    "            else:\n",
    "                X = X_ttl\n",
    "            # Predict base models\n",
    "            prob_kfold = pd.DataFrame()\n",
    "            for j, model in enumerate(models_kfold):\n",
    "                prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "            meta_features[i] = prob_kfold.mean(axis=1)\n",
    "        # Feature with Null\n",
    "        for k, models_kfold in enumerate(self.base_models_na_):\n",
    "            i += 1\n",
    "            # If select features\n",
    "            if self.if_feats_select == True:\n",
    "                X = Xna_ttl[self.base_feats[i]]\n",
    "            else:\n",
    "                X = Xna_ttl\n",
    "            # Predict base models\n",
    "            prob_kfold = pd.DataFrame()\n",
    "            for j, model in enumerate(models_kfold):\n",
    "                prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "            meta_features[i] = prob_kfold.mean(axis=1)\n",
    "        \n",
    "        # Prediect\n",
    "        if if_meta:\n",
    "            # Polynomial\n",
    "            poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "            X = poly.fit_transform(meta_features)\n",
    "            prob_kfold = pd.DataFrame()\n",
    "            for j, model in enumerate(self.meta_models_):\n",
    "                prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "            pred = prob_kfold.mean(axis=1)\n",
    "        else:\n",
    "            pred = meta_features.mean(axis=1)\n",
    "        return pred\n",
    "    \n",
    "############ Stacking\n",
    "\n",
    "### Base models\n",
    "\n",
    "# Base Featues\n",
    "''' Load Features '''\n",
    "feats = np.load('./model/base_features.npy', allow_pickle=True).item()\n",
    "for k, v in feats.items():\n",
    "    print(f'{k}:{len(v)}')\n",
    "\n",
    "# RF = RandomForestClassifier()\n",
    "# XGB = XGBClassifier()\n",
    "# LGB = LGBMClassifier()\n",
    "# LR = LogisticRegression()\n",
    "\n",
    "# RF\n",
    "best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_rf}\n",
    "RF = RandomForestClassifier(**model_params)\n",
    "# XGB\n",
    "best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_xgb}\n",
    "XGB = XGBClassifier(**model_params)\n",
    "# LGB\n",
    "best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lgb}\n",
    "LGB = LGBMClassifier(**model_params)\n",
    "LGBNA = clone(LGB)\n",
    "# LR\n",
    "best_params_load = np.load('./model/base_lr.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lr}\n",
    "LR = LogisticRegression(**model_params)\n",
    "# Mean\n",
    "MEAN = 'MEAN'\n",
    "\n",
    "### Stacking\n",
    "base_models_na = [LGBNA]\n",
    "\n",
    "base_models = [LGB, RF, XGB, LR]\n",
    "base_feats = [feats['lgb'], feats['rf'], feats['xgb'], feats['corr'], feats['lgbna']]\n",
    "# base_models = [LR]\n",
    "# base_feats = [feats['corr'], []]\n",
    "\n",
    "meta_model = LR\n",
    "CLF = StackingModels(base_models=base_models, base_models_na=base_models_na,\n",
    "                     meta_model=meta_model, base_feats=base_feats, if_feats_select=True)\n",
    "\n",
    "# Fit\n",
    "CLF.fit(X, X1, y)\n",
    "\n",
    "# # Predict\n",
    "# pred = CLF.predict(X)\n",
    "# ks_score(y, pred)\n",
    "\n",
    "# # Save meta_X\n",
    "# meta_X = pd.DataFrame(CLF.meta_X, columns=['lgb', 'rf', 'xgb', 'lgbna'])\n",
    "# meta_X.shape\n",
    "# meta_X.head()\n",
    "# meta_X.to_csv('./model/x_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21469, 811)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(21469, 811)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>申请编号</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.240715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.585614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.068014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>0.122484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>0.043567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   申请编号         0\n",
       "0     4  0.240715\n",
       "1     6  0.585614\n",
       "2    16  0.068014\n",
       "3    17  0.122484\n",
       "4    38  0.043567"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Test\n",
    "\n",
    "def norm_score(score):\n",
    "    if score < 0:\n",
    "        score = 0\n",
    "    elif score > 1:\n",
    "        score = 1\n",
    "    return score\n",
    "\n",
    "test = pd.read_csv('./tmp/A_d1234_nona.csv', header=0, index_col=0)\n",
    "X_test = test.drop(uid, axis=1)\n",
    "X_test.shape\n",
    "test_na = pd.read_csv('./tmp/A_d1234_na.csv', header=0, index_col=0)\n",
    "X_test_na = test_na.drop(uid, axis=1)\n",
    "X_test_na.shape\n",
    "\n",
    "# Predict\n",
    "scores = CLF.predict(X_test, X_test_na)\n",
    "\n",
    "# Output\n",
    "uids = test[uid]\n",
    "out = pd.concat([uids, pd.Series(scores)], axis=1)\n",
    "out[0] = out[0].apply(norm_score)\n",
    "out.head()\n",
    "out.to_csv('./model/predict.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ############## Predict Train\n",
    "\n",
    "# def norm_score(score):\n",
    "#     if score < 0:\n",
    "#         score = 0\n",
    "#     elif score > 1:\n",
    "#         score = 1\n",
    "#     return score\n",
    "\n",
    "# # Predict\n",
    "# scores = CLF.predict(Xid)\n",
    "\n",
    "# # Output\n",
    "# uids = Xid[uid]\n",
    "# out = pd.concat([uids, pd.Series(scores)], axis=1)\n",
    "# out[0] = out[0].apply(norm_score)\n",
    "# out.head()\n",
    "# out.to_csv('./model/predict_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Distributions\n",
    "\n",
    "# # Final\n",
    "# sns.distplot(pred)\n",
    "# sns.distplot(scores)\n",
    "# plt.show()\n",
    "\n",
    "# meta_X = CLF.meta_X\n",
    "# meta_X.shape\n",
    "# meta_X[0]\n",
    "\n",
    "# # Base\n",
    "# for i in range(3):\n",
    "#     i\n",
    "#     sns.distplot(meta_X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############## Ana\n",
    "\n",
    "# base_models = [LGB, RF, XGB]\n",
    "# base_models_ = [list() for x in base_models]\n",
    "# kfold = KFold(n_splits=2, shuffle=True, random_state=123)\n",
    "\n",
    "# out_of_fold_predictions = np.zeros((X.shape[0], len(base_models)))\n",
    "# for i, model in enumerate(base_models):\n",
    "#     j = 0\n",
    "#     for train_index, valid_index in kfold.split(X, y):\n",
    "#         instance = clone(model)\n",
    "#         base_models_[i].append(instance)\n",
    "#         instance.fit(X.loc[train_index],  y.loc[train_index])\n",
    "#         len(X.loc[train_index])\n",
    "#         y_pred = instance.predict_proba(X.loc[valid_index])[:,1]\n",
    "#         ks = ks_score(y.loc[valid_index], y_pred)\n",
    "#         print(f'* KS({j}):{ks} *')\n",
    "#         out_of_fold_predictions[valid_index, i] = y_pred\n",
    "#         j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(out_of_fold_predictions)\n",
    "# len(out_of_fold_predictions[0])\n",
    "# out_of_fold_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_model = LR\n",
    "# meta_model_ = clone(meta_model)\n",
    "\n",
    "# meta_model_.fit(out_of_fold_predictions, y)\n",
    "# y_pred = meta_model_.predict_proba(out_of_fold_predictions)[:,1]\n",
    "# ks_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features = np.column_stack ([\n",
    "#     np.column_stack(\n",
    "#         [model.predict_proba(X)[:,1] for model in base_models]\n",
    "#     ).mean (axis=1)\n",
    "#     for base_models in base_models_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(meta_features)\n",
    "# len(meta_features[0])\n",
    "# meta_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features = pd.DataFrame()\n",
    "# for i, models_kfold in enumerate(base_models_):\n",
    "#     i\n",
    "#     prob_kfold = pd.DataFrame()\n",
    "#     for j, model in enumerate(models_kfold):\n",
    "#         j\n",
    "#         prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "#         prob_kfold.shape\n",
    "#     prob_kfold.head()\n",
    "#     meta_features[i] = prob_kfold.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features.shape\n",
    "# meta_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' RF '''\n",
    "# RF.fit(meta_features, y)\n",
    "# ks_score(y, RF.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' RF1 '''\n",
    "# RF1 = RandomForestClassifier()\n",
    "# RF1.fit(meta_features, y)\n",
    "# ks_score(y, RF1.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' LGB '''\n",
    "# LGB.fit(meta_features, y)\n",
    "# ks_score(y, LGB.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' LR '''\n",
    "# LR.fit(meta_features, y)\n",
    "# ks_score(y, LR.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' MEAN '''\n",
    "# # LR.fit(meta_features, y)\n",
    "# ks_score(y, meta_features.mean(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
