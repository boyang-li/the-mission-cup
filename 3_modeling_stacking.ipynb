{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Meng/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats as spstats\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, PolynomialFeatures, StandardScaler, scale as skscale\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Load '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Merge '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' drop id'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Split '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 811)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Load\n",
    "\n",
    "# For kfold\n",
    "n_folds = 5\n",
    "\n",
    "# ### Test\n",
    "# X = pd.read_csv('./tmp/train_d1234.csv', header=0, index_col=0).head(10000)\n",
    "# X.shape\n",
    "\n",
    "# y = pd.read_csv('./data/train_label.csv', header=0, index_col=0).head(10000)\n",
    "# y.shape\n",
    "\n",
    "''' Load '''\n",
    "Xid = pd.read_csv('./tmp/train_d1234_nona.csv', header=0, index_col=0)\n",
    "Xid.shape\n",
    "\n",
    "yid = pd.read_csv('./data/train_label.csv', header=0, index_col=0)\n",
    "yid.shape\n",
    "\n",
    "''' Merge '''\n",
    "# Merge\n",
    "xy = pd.merge(Xid, yid, on=uid, how='inner')\n",
    "\n",
    "# ''' Filter Bins ''' \n",
    "# uids = pd.read_csv('./tmp/train_uid0.csv', header=0, index_col=0)\n",
    "# uids.columns = [uid]\n",
    "# xy = pd.merge(uids, xy, on=uid, how='left')\n",
    "# xy.shape\n",
    "\n",
    "''' drop id'''\n",
    "xy.drop(uid, axis=1, inplace=True)\n",
    "xy.shape\n",
    "\n",
    "''' Split '''\n",
    "# X, y\n",
    "X = xy.copy()\n",
    "y = X.pop(target)\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "# ### List\n",
    "# X = pd.read_csv('./tmp/train_d12_d3_dum.csv', header=0, index_col=0).drop(uid, axis=1).values\n",
    "# len(X)\n",
    "# len(X[0])\n",
    "\n",
    "# y = pd.read_csv('./tmp/1_y.csv', header=0, index_col=0)['0'].values\n",
    "# len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "param_fixed_rf = {\n",
    "    'n_jobs' : -1,\n",
    "    'oob_score' : True,\n",
    "    'random_state':123,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_fixed_xgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'seed' : 123,\n",
    "    'silent' : 1,\n",
    "    'verbose_eval':0\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_fixed_lgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'metric' : 'auc',\n",
    "    'random_state' : 123,\n",
    "    'bagging_seed':123,\n",
    "    'feature_fraction_seed':123,\n",
    "    'verbose_eval' : 0\n",
    "}\n",
    "\n",
    "# LR\n",
    "param_fixed_lr = {\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 123,\n",
    "    'verbose' : 0     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Base Model: <class 'lightgbm.sklearn.LGBMClassifier'>, Features: 811 ***\n",
      "0.3716\n",
      "0.3711\n",
      "0.3528\n",
      "0.3653\n",
      "0.3532\n",
      "*** Base Model: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, Features: 811 ***\n",
      "0.3116\n",
      "0.302\n",
      "0.3061\n",
      "0.3066\n",
      "0.3042\n",
      "*** Base Model: <class 'xgboost.sklearn.XGBClassifier'>, Features: 811 ***\n",
      "0.3581\n",
      "0.3565\n",
      "0.3484\n",
      "0.35\n",
      "0.353\n",
      "*** Meta Model: <class 'sklearn.linear_model.logistic.LogisticRegression'>, Features: 6 ***\n",
      "0.3733\n",
      "0.3707\n",
      "0.3533\n",
      "0.3673\n",
      "0.3557\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingModels(base_feats=[],\n",
       "               base_models=[LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,\n",
       "                                           bagging_seed=123,\n",
       "                                           boosting_type='gbdt', cat_smooth=16,\n",
       "                                           class_weight=None,\n",
       "                                           colsample_bytree=1.0,\n",
       "                                           feature_fraction=0.9,\n",
       "                                           feature_fraction_seed=123,\n",
       "                                           importance_type='split',\n",
       "                                           is_unbalance=True,\n",
       "                                           lambda_l1=0.8888888888888888,\n",
       "                                           lambda_l2=25, learning_rate=0.02,\n",
       "                                           max_depth=-1, met...\n",
       "                                          reg_lambda=1, scale_pos_weight=1,\n",
       "                                          seed=123, silent=1, subsample=0.8,\n",
       "                                          verbose_eval=0, verbosity=1)],\n",
       "               if_feats_select=False,\n",
       "               meta_model=LogisticRegression(C=0.1, class_weight=1, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='warn',\n",
       "                                             n_jobs=-1, penalty='l2',\n",
       "                                             random_state=123, solver='lbfgs',\n",
       "                                             tol=0.0001, verbose=0,\n",
       "                                             warm_start=False),\n",
       "               n_folds=5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StackingModels (BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, base_feats, meta_model, if_feats_select, n_folds = n_folds):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.if_feats_select = if_feats_select\n",
    "        # base_feats\n",
    "        self.base_feats = []\n",
    "        if self.if_feats_select == True:\n",
    "            self.base_feats = base_feats\n",
    "        self.n_folds = n_folds\n",
    "        self.meta_X = []\n",
    "\n",
    "    def fit(self, X_ttl, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=123)\n",
    "        \n",
    "        # Get results of basic models\n",
    "        out_of_fold_predictions = np.zeros((X_ttl.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            ### If select features\n",
    "            if self.if_feats_select == True:\n",
    "                X = X_ttl[self.base_feats[i]]\n",
    "            else:\n",
    "                X = X_ttl\n",
    "            l = len(X.columns) # Feature count\n",
    "            print(f'*** Base Model: {model.__class__}, Features: {l} ***')\n",
    "            \n",
    "            j = 0\n",
    "            # Train\n",
    "            for train_index, valid_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X.iloc[train_index],  y.iloc[train_index])\n",
    "                y_pred = instance.predict_proba(X.iloc[valid_index])[:,1]\n",
    "                ks = ks_score(y.iloc[valid_index], y_pred)\n",
    "                print(ks)\n",
    "                out_of_fold_predictions[valid_index, i] = y_pred\n",
    "                j += 1\n",
    "\n",
    "        # META\n",
    "        self.meta_X = out_of_fold_predictions\n",
    "        # Polynomial\n",
    "        poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "        X = poly.fit_transform(out_of_fold_predictions)\n",
    "        l = len(X[0]) # Feature Count\n",
    "        print(f'*** Meta Model: {self.meta_model.__class__}, Features: {l} ***')\n",
    "        j = 0\n",
    "        self.meta_models_ = []\n",
    "        for train_index, valid_index in kfold.split(X, y):\n",
    "            instance = clone(self.meta_model)\n",
    "            self.meta_models_.append(instance)\n",
    "            instance.fit(X[train_index],  y[train_index])\n",
    "            y_pred = instance.predict_proba(X[valid_index])[:,1]\n",
    "            ks = ks_score(y[valid_index], y_pred)\n",
    "            print(ks)\n",
    "            j += 1\n",
    "        return self\n",
    "\n",
    "    # Prediect\n",
    "    def predict(self, X_ttl, if_meta=True):\n",
    "        \n",
    "        # Features for Meta Model       \n",
    "        meta_features = pd.DataFrame()\n",
    "        for i, models_kfold in enumerate(self.base_models_):\n",
    "            # If select features\n",
    "            if self.if_feats_select == True:\n",
    "                X = X_ttl[self.base_feats[i]]\n",
    "            else:\n",
    "                X = X_ttl\n",
    "            # Predict base models\n",
    "            prob_kfold = pd.DataFrame()\n",
    "            for j, model in enumerate(models_kfold):\n",
    "                prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "            meta_features[i] = prob_kfold.mean(axis=1)\n",
    "        \n",
    "        # Prediect\n",
    "        if if_meta:\n",
    "            # Polynomial\n",
    "            poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "            X = poly.fit_transform(meta_features)\n",
    "            prob_kfold = pd.DataFrame()\n",
    "            for j, model in enumerate(self.meta_models_):\n",
    "                prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "            pred = prob_kfold.mean(axis=1)\n",
    "        else:\n",
    "            pred = meta_features.mean(axis=1)\n",
    "        return pred\n",
    "    \n",
    "############ Stacking\n",
    "\n",
    "### Base models\n",
    "\n",
    "# Base Featues\n",
    "feats = np.load('./model/base_features.npy', allow_pickle=True).item()\n",
    "\n",
    "# RF = RandomForestClassifier()\n",
    "# XGB = XGBClassifier()\n",
    "# LGB = LGBMClassifier()\n",
    "# LR = LogisticRegression()\n",
    "\n",
    "# RF\n",
    "best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_rf}\n",
    "RF = RandomForestClassifier(**model_params)\n",
    "# XGB\n",
    "best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_xgb}\n",
    "XGB = XGBClassifier(**model_params)\n",
    "# LGB\n",
    "best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lgb}\n",
    "LGB = LGBMClassifier(**model_params)\n",
    "# LR\n",
    "best_params_load = np.load('./model/base_lr.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lr}\n",
    "LR = LogisticRegression(**model_params)\n",
    "# Mean\n",
    "MEAN = 'MEAN'\n",
    "\n",
    "### Stacking\n",
    "base_models = [LGB, RF, XGB]\n",
    "base_feats = [feats['lgb'], feats['rf'], feats['xgb']]\n",
    "# base_models = [LGB, XGB]\n",
    "# base_feats = [feats['lgb'], feats['xgb']]\n",
    "meta_model = LR\n",
    "CLF = StackingModels(base_models=base_models, meta_model=meta_model, base_feats=base_feats, if_feats_select=False)\n",
    "\n",
    "# Fit\n",
    "CLF.fit(X, y)\n",
    "\n",
    "# # Predict\n",
    "# pred = CLF.predict(X)\n",
    "# ks_score(y, pred)\n",
    "\n",
    "# # Save meta_X\n",
    "# meta_X = pd.DataFrame(CLF.meta_X, columns=['lgb', 'rf', 'xgb'])\n",
    "# # meta_X = pd.DataFrame(CLF.meta_X, columns=['lgb', 'xgb'])\n",
    "# meta_X.shape\n",
    "# meta_X.head()\n",
    "# meta_X.to_csv('./model/x_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StackingModels (BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "#     def __init__(self, base_models, base_feats, meta_model, n_folds = n_folds):\n",
    "#         self.base_models = base_models\n",
    "#         self.base_feats = base_feats\n",
    "#         self.meta_model = meta_model\n",
    "#         self.n_folds = n_folds\n",
    "#         self.meta_X = []\n",
    "\n",
    "#     def fit(self, X_ttl, y):\n",
    "#         self.base_models_ = [list() for x in self.base_models]\n",
    "#         kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=123)\n",
    "        \n",
    "#         # Get results of basic models\n",
    "#         out_of_fold_predictions = np.zeros((X_ttl.shape[0], len(self.base_models)))\n",
    "#         for i, model in enumerate(self.base_models):\n",
    "#             l = len(self.base_feats[i]) # Feature Count\n",
    "#             print(f'*** Base Model: {model.__class__}, Features: {l} ***')\n",
    "#             j = 0\n",
    "#             X = X_ttl[self.base_feats[i]]\n",
    "#             for train_index, valid_index in kfold.split(X, y):\n",
    "#                 instance = clone(model)\n",
    "#                 self.base_models_[i].append(instance)\n",
    "#                 instance.fit(X.iloc[train_index],  y.iloc[train_index])\n",
    "#                 y_pred = instance.predict_proba(X.iloc[valid_index])[:,1]\n",
    "#                 ks = ks_score(y.iloc[valid_index], y_pred)\n",
    "#                 print(ks)\n",
    "#                 out_of_fold_predictions[valid_index, i] = y_pred\n",
    "#                 j += 1\n",
    "\n",
    "#         # META\n",
    "#         self.meta_X = out_of_fold_predictions\n",
    "#         # Polynomial\n",
    "#         poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "#         X = poly.fit_transform(out_of_fold_predictions)\n",
    "#         l = len(X[0]) # Feature Count\n",
    "#         print(f'*** Meta Model: {self.meta_model.__class__}, Features: {l} ***')\n",
    "#         j = 0\n",
    "#         self.meta_models_ = []\n",
    "#         for train_index, valid_index in kfold.split(X, y):\n",
    "#             instance = clone(self.meta_model)\n",
    "#             self.meta_models_.append(instance)\n",
    "#             instance.fit(X[train_index],  y[train_index])\n",
    "#             y_pred = instance.predict_proba(X[valid_index])[:,1]\n",
    "#             ks = ks_score(y[valid_index], y_pred)\n",
    "#             print(ks)\n",
    "#             j += 1\n",
    "#         return self\n",
    "\n",
    "#     # Prediect\n",
    "#     def predict(self, X_ttl, if_meta=True):\n",
    "        \n",
    "#         # Features for Meta Model       \n",
    "#         meta_features = pd.DataFrame()\n",
    "#         for i, models_kfold in enumerate(self.base_models_):\n",
    "#             X = X_ttl[self.base_feats[i]] \n",
    "#             prob_kfold = pd.DataFrame()\n",
    "#             for j, model in enumerate(models_kfold):\n",
    "#                 prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "#             meta_features[i] = prob_kfold.mean(axis=1)\n",
    "        \n",
    "#         # Prediect\n",
    "#         if if_meta:\n",
    "#             # Polynomial\n",
    "#             poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "#             X = poly.fit_transform(meta_features)\n",
    "#             prob_kfold = pd.DataFrame()\n",
    "#             for j, model in enumerate(self.meta_models_):\n",
    "#                 prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "#             pred = prob_kfold.mean(axis=1)\n",
    "#         else:\n",
    "#             pred = meta_features.mean(axis=1)\n",
    "#         return pred\n",
    "    \n",
    "# ############ Stacking\n",
    "\n",
    "# ### Base models\n",
    "\n",
    "# # Base Featues\n",
    "# feats = np.load('./model/base_features.npy', allow_pickle=True).item()\n",
    "\n",
    "# # RF = RandomForestClassifier()\n",
    "# # XGB = XGBClassifier()\n",
    "# # LGB = LGBMClassifier()\n",
    "# # LR = LogisticRegression()\n",
    "\n",
    "# # RF\n",
    "# best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "# model_params = {**best_params_load, **param_fixed_rf}\n",
    "# RF = RandomForestClassifier(**model_params)\n",
    "# # XGB\n",
    "# best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "# model_params = {**best_params_load, **param_fixed_xgb}\n",
    "# XGB = XGBClassifier(**model_params)\n",
    "# # LGB\n",
    "# best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "# model_params = {**best_params_load, **param_fixed_lgb}\n",
    "# LGB = LGBMClassifier(**model_params)\n",
    "# # LR\n",
    "# best_params_load = np.load('./model/base_lr.npy', allow_pickle=True).item()\n",
    "# model_params = {**best_params_load, **param_fixed_lr}\n",
    "# LR = LogisticRegression(**model_params)\n",
    "# # Mean\n",
    "# MEAN = 'MEAN'\n",
    "\n",
    "# ### Stacking\n",
    "# base_models = [LGB, RF, XGB]\n",
    "# base_feats = [feats['lgb'], feats['rf'], feats['xgb']]\n",
    "# # base_models = [LGB, XGB]\n",
    "# # base_feats = [feats['lgb'], feats['xgb']]\n",
    "# meta_model = LR\n",
    "# CLF = StackingModels(base_models=base_models, base_feats=base_feats, meta_model=meta_model)\n",
    "\n",
    "# # Fit\n",
    "# CLF.fit(X, y)\n",
    "\n",
    "# # # Predict\n",
    "# # pred = CLF.predict(X)\n",
    "# # ks_score(y, pred)\n",
    "\n",
    "# # # Save meta_X\n",
    "# # meta_X = pd.DataFrame(CLF.meta_X, columns=['lgb', 'rf', 'xgb'])\n",
    "# # # meta_X = pd.DataFrame(CLF.meta_X, columns=['lgb', 'xgb'])\n",
    "# # meta_X.shape\n",
    "# # meta_X.head()\n",
    "# # meta_X.to_csv('./model/x_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Test\n",
    "\n",
    "def norm_score(score):\n",
    "    if score < 0:\n",
    "        score = 0\n",
    "    elif score > 1:\n",
    "        score = 1\n",
    "    return score\n",
    "\n",
    "test = pd.read_csv('./tmp/A_d1234.csv', header=0, index_col=0)\n",
    "X_test = test.drop(uid, axis=1)\n",
    "X_test.shape\n",
    "\n",
    "# Predict\n",
    "scores = CLF.predict(X_test)\n",
    "\n",
    "# Output\n",
    "uids = test[uid]\n",
    "out = pd.concat([uids, pd.Series(scores)], axis=1)\n",
    "out[0] = out[0].apply(norm_score)\n",
    "out.head()\n",
    "out.to_csv('./model/predict.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ############## Predict Train\n",
    "\n",
    "# def norm_score(score):\n",
    "#     if score < 0:\n",
    "#         score = 0\n",
    "#     elif score > 1:\n",
    "#         score = 1\n",
    "#     return score\n",
    "\n",
    "# # Predict\n",
    "# scores = CLF.predict(Xid)\n",
    "\n",
    "# # Output\n",
    "# uids = Xid[uid]\n",
    "# out = pd.concat([uids, pd.Series(scores)], axis=1)\n",
    "# out[0] = out[0].apply(norm_score)\n",
    "# out.head()\n",
    "# out.to_csv('./model/predict_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Distributions\n",
    "\n",
    "# # Final\n",
    "# sns.distplot(pred)\n",
    "# sns.distplot(scores)\n",
    "# plt.show()\n",
    "\n",
    "# meta_X = CLF.meta_X\n",
    "# meta_X.shape\n",
    "# meta_X[0]\n",
    "\n",
    "# # Base\n",
    "# for i in range(3):\n",
    "#     i\n",
    "#     sns.distplot(meta_X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############## Ana\n",
    "\n",
    "# base_models = [LGB, RF, XGB]\n",
    "# base_models_ = [list() for x in base_models]\n",
    "# kfold = KFold(n_splits=2, shuffle=True, random_state=123)\n",
    "\n",
    "# out_of_fold_predictions = np.zeros((X.shape[0], len(base_models)))\n",
    "# for i, model in enumerate(base_models):\n",
    "#     j = 0\n",
    "#     for train_index, valid_index in kfold.split(X, y):\n",
    "#         instance = clone(model)\n",
    "#         base_models_[i].append(instance)\n",
    "#         instance.fit(X.loc[train_index],  y.loc[train_index])\n",
    "#         len(X.loc[train_index])\n",
    "#         y_pred = instance.predict_proba(X.loc[valid_index])[:,1]\n",
    "#         ks = ks_score(y.loc[valid_index], y_pred)\n",
    "#         print(f'* KS({j}):{ks} *')\n",
    "#         out_of_fold_predictions[valid_index, i] = y_pred\n",
    "#         j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(out_of_fold_predictions)\n",
    "# len(out_of_fold_predictions[0])\n",
    "# out_of_fold_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_model = LR\n",
    "# meta_model_ = clone(meta_model)\n",
    "\n",
    "# meta_model_.fit(out_of_fold_predictions, y)\n",
    "# y_pred = meta_model_.predict_proba(out_of_fold_predictions)[:,1]\n",
    "# ks_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features = np.column_stack ([\n",
    "#     np.column_stack(\n",
    "#         [model.predict_proba(X)[:,1] for model in base_models]\n",
    "#     ).mean (axis=1)\n",
    "#     for base_models in base_models_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(meta_features)\n",
    "# len(meta_features[0])\n",
    "# meta_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features = pd.DataFrame()\n",
    "# for i, models_kfold in enumerate(base_models_):\n",
    "#     i\n",
    "#     prob_kfold = pd.DataFrame()\n",
    "#     for j, model in enumerate(models_kfold):\n",
    "#         j\n",
    "#         prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "#         prob_kfold.shape\n",
    "#     prob_kfold.head()\n",
    "#     meta_features[i] = prob_kfold.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features.shape\n",
    "# meta_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' RF '''\n",
    "# RF.fit(meta_features, y)\n",
    "# ks_score(y, RF.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' RF1 '''\n",
    "# RF1 = RandomForestClassifier()\n",
    "# RF1.fit(meta_features, y)\n",
    "# ks_score(y, RF1.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' LGB '''\n",
    "# LGB.fit(meta_features, y)\n",
    "# ks_score(y, LGB.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' LR '''\n",
    "# LR.fit(meta_features, y)\n",
    "# ks_score(y, LR.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' MEAN '''\n",
    "# # LR.fit(meta_features, y)\n",
    "# ks_score(y, meta_features.mean(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
