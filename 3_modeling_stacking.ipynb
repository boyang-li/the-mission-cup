{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Meng/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats as spstats\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, PolynomialFeatures, StandardScaler, scale as skscale\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Load '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 802)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Merge '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 802)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Split '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 801)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Load\n",
    "\n",
    "# For kfold\n",
    "n_folds = 5\n",
    "\n",
    "# ### Test\n",
    "# X = pd.read_csv('./tmp/train_d1234.csv', header=0, index_col=0).head(10000)\n",
    "# X.shape\n",
    "\n",
    "# y = pd.read_csv('./data/train_label.csv', header=0, index_col=0).head(10000)\n",
    "# y.shape\n",
    "\n",
    "''' Load '''\n",
    "X = pd.read_csv('./tmp/train_d1234.csv', header=0, index_col=0)\n",
    "X.shape\n",
    "\n",
    "y = pd.read_csv('./data/train_label.csv', header=0, index_col=0)\n",
    "y.shape\n",
    "\n",
    "''' Merge '''\n",
    "# Merge\n",
    "xy = pd.merge(X, y, on=uid, how='inner')\n",
    "xy.drop(uid, axis=1, inplace=True)\n",
    "xy.shape\n",
    "\n",
    "''' Split '''\n",
    "# X, y\n",
    "X = xy.copy()\n",
    "y = X.pop(target)\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "# ### List\n",
    "# X = pd.read_csv('./tmp/train_d12_d3_dum.csv', header=0, index_col=0).drop(uid, axis=1).values\n",
    "# len(X)\n",
    "# len(X[0])\n",
    "\n",
    "# y = pd.read_csv('./tmp/1_y.csv', header=0, index_col=0)['0'].values\n",
    "# len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "param_fixed_rf = {\n",
    "    'n_jobs' : -1,\n",
    "    'oob_score' : True,\n",
    "    'random_state':123,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_fixed_xgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'seed' : 123,\n",
    "    'silent' : 1,\n",
    "    'verbose_eval':0\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_fixed_lgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'metric' : 'auc',\n",
    "    'random_state' : 123,\n",
    "    'bagging_seed':123,\n",
    "    'feature_fraction_seed':123,\n",
    "    'verbose_eval' : 0\n",
    "}\n",
    "\n",
    "# LR\n",
    "param_fixed_lr = {\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 123,\n",
    "    'verbose' : 0     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Base Model: <class 'lightgbm.sklearn.LGBMClassifier'>, Features: 801 ***\n",
      "0.3733\n",
      "0.3672\n",
      "0.3606\n",
      "0.3654\n",
      "0.3556\n",
      "*** Base Model: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, Features: 801 ***\n",
      "0.31\n",
      "0.2955\n",
      "0.3002\n",
      "0.3082\n",
      "0.3035\n",
      "*** Base Model: <class 'xgboost.sklearn.XGBClassifier'>, Features: 801 ***\n",
      "0.3621\n",
      "0.3583\n",
      "0.3574\n",
      "0.359\n",
      "0.3459\n",
      "*** Meta Model: <class 'sklearn.linear_model.logistic.LogisticRegression'>, Features: 6 ***\n",
      "0.3774\n",
      "0.3691\n",
      "0.3624\n",
      "0.3683\n",
      "0.3584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingModels(base_feats=[{'产品类型_0mean_x', '产品类型_0mean_y', '产品类型_0sum_x',\n",
       "                            '产品类型_0sum_y', '产品类型_1mean_x', '产品类型_1mean_y',\n",
       "                            '产品类型_1sum_x', '产品类型_1sum_y', '产品类型_2mean_x',\n",
       "                            '产品类型_2mean_y', '产品类型_2sum_x', '产品类型_2sum_y',\n",
       "                            '产品组合_0.0mean_x', '产品组合_0.0mean_y', '产品组合_0.0sum_x',\n",
       "                            '产品组合_0.0sum_y', '产品组合_1.0mean_x', '产品组合_1.0mean_y',\n",
       "                            '产品组合_1.0sum_x', '产品组合_1.0sum_y', '产品组合_10.0mean_x...\n",
       "                                          random_state=0, reg_alpha=0,\n",
       "                                          reg_lambda=1, scale_pos_weight=1,\n",
       "                                          seed=123, silent=1, subsample=0.8,\n",
       "                                          verbose_eval=0, verbosity=1)],\n",
       "               meta_model=LogisticRegression(C=0.1, class_weight=1, dual=False,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1, l1_ratio=None,\n",
       "                                             max_iter=100, multi_class='warn',\n",
       "                                             n_jobs=-1, penalty='l2',\n",
       "                                             random_state=123, solver='lbfgs',\n",
       "                                             tol=0.0001, verbose=0,\n",
       "                                             warm_start=False),\n",
       "               n_folds=5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7393"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgb</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.611641</td>\n",
       "      <td>0.518803</td>\n",
       "      <td>0.288619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.535263</td>\n",
       "      <td>0.631210</td>\n",
       "      <td>0.322010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.577945</td>\n",
       "      <td>0.621527</td>\n",
       "      <td>0.276926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.218198</td>\n",
       "      <td>0.352988</td>\n",
       "      <td>0.069108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110205</td>\n",
       "      <td>0.449190</td>\n",
       "      <td>0.034979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lgb        rf       xgb\n",
       "0  0.611641  0.518803  0.288619\n",
       "1  0.535263  0.631210  0.322010\n",
       "2  0.577945  0.621527  0.276926\n",
       "3  0.218198  0.352988  0.069108\n",
       "4  0.110205  0.449190  0.034979"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StackingModels (BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, base_feats, meta_model, n_folds = n_folds):\n",
    "        self.base_models = base_models\n",
    "        self.base_feats = base_feats\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "        self.meta_X = []\n",
    "\n",
    "    def fit(self, X_ttl, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=123)\n",
    "        \n",
    "        # Get results of basic models\n",
    "        out_of_fold_predictions = np.zeros((X_ttl.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            l = len(self.base_feats[i]) # Feature Count\n",
    "            print(f'*** Base Model: {model.__class__}, Features: {l} ***')\n",
    "            j = 0\n",
    "            X = X_ttl[self.base_feats[i]]\n",
    "            for train_index, valid_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X.iloc[train_index],  y.iloc[train_index])\n",
    "                y_pred = instance.predict_proba(X.iloc[valid_index])[:,1]\n",
    "                ks = ks_score(y.iloc[valid_index], y_pred)\n",
    "                print(ks)\n",
    "                out_of_fold_predictions[valid_index, i] = y_pred\n",
    "                j += 1\n",
    "\n",
    "        # META\n",
    "        self.meta_X = out_of_fold_predictions\n",
    "        # Polynomial\n",
    "        poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "        X = poly.fit_transform(out_of_fold_predictions)\n",
    "        l = len(X[0]) # Feature Count\n",
    "        print(f'*** Meta Model: {self.meta_model.__class__}, Features: {l} ***')\n",
    "        j = 0\n",
    "        self.meta_models_ = []\n",
    "        for train_index, valid_index in kfold.split(X, y):\n",
    "            instance = clone(self.meta_model)\n",
    "            self.meta_models_.append(instance)\n",
    "            instance.fit(X[train_index],  y[train_index])\n",
    "            y_pred = instance.predict_proba(X[valid_index])[:,1]\n",
    "            ks = ks_score(y[valid_index], y_pred)\n",
    "            print(ks)\n",
    "            j += 1\n",
    "        return self\n",
    "\n",
    "    # Prediect\n",
    "    def predict(self, X_ttl, if_meta=True):\n",
    "        \n",
    "        # Features for Meta Model       \n",
    "        meta_features = pd.DataFrame()\n",
    "        for i, models_kfold in enumerate(self.base_models_):\n",
    "            X = X_ttl[self.base_feats[i]] \n",
    "            prob_kfold = pd.DataFrame()\n",
    "            for j, model in enumerate(models_kfold):\n",
    "                prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "            meta_features[i] = prob_kfold.mean(axis=1)\n",
    "        \n",
    "        # Prediect\n",
    "        if if_meta:\n",
    "            # Polynomial\n",
    "            poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "            X = poly.fit_transform(meta_features)\n",
    "            prob_kfold = pd.DataFrame()\n",
    "            for j, model in enumerate(self.meta_models_):\n",
    "                prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "            pred = prob_kfold.mean(axis=1)\n",
    "        else:\n",
    "            pred = meta_features.mean(axis=1)\n",
    "        return pred\n",
    "    \n",
    "############ Stacking\n",
    "\n",
    "### Base models\n",
    "\n",
    "# Base Featues\n",
    "feats = np.load('./model/base_features.npy', allow_pickle=True).item()\n",
    "\n",
    "# RF = RandomForestClassifier()\n",
    "# XGB = XGBClassifier()\n",
    "# LGB = LGBMClassifier()\n",
    "# LR = LogisticRegression()\n",
    "\n",
    "# RF\n",
    "best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_rf}\n",
    "RF = RandomForestClassifier(**model_params)\n",
    "# XGB\n",
    "best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_xgb}\n",
    "XGB = XGBClassifier(**model_params)\n",
    "# LGB\n",
    "best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lgb}\n",
    "LGB = LGBMClassifier(**model_params)\n",
    "# LR\n",
    "best_params_load = np.load('./model/base_lr.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lr}\n",
    "LR = LogisticRegression(**model_params)\n",
    "# Mean\n",
    "MEAN = 'MEAN'\n",
    "\n",
    "### Stacking\n",
    "base_models = [LGB, RF, XGB]\n",
    "base_feats = [feats['lgb'], feats['rf'], feats['xgb']]\n",
    "# base_models = [LGB, XGB]\n",
    "# base_feats = [feats['lgb'], feats['xgb']]\n",
    "meta_model = LR\n",
    "CLF = StackingModels(base_models=base_models, base_feats=base_feats, meta_model=meta_model)\n",
    "\n",
    "# Fit\n",
    "CLF.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "pred = CLF.predict(X)\n",
    "ks_score(y, pred)\n",
    "\n",
    "# Save meta_X\n",
    "meta_X = pd.DataFrame(CLF.meta_X, columns=['lgb', 'rf', 'xgb'])\n",
    "# meta_X = pd.DataFrame(CLF.meta_X, columns=['lgb', 'xgb'])\n",
    "meta_X.shape\n",
    "meta_X.head()\n",
    "meta_X.to_csv('./model/x_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############## Test\n",
    "\n",
    "# def norm_score(score):\n",
    "#     if score < 0:\n",
    "#         score = 0\n",
    "#     elif score > 1:\n",
    "#         score = 1\n",
    "#     return score\n",
    "\n",
    "# test = pd.read_csv('./tmp/A_d1234.csv', header=0, index_col=0)\n",
    "# X_test = test.drop(uid, axis=1)\n",
    "# X_test.shape\n",
    "\n",
    "# # Predict\n",
    "# scores = CLF.predict(X_test)\n",
    "\n",
    "# # Output\n",
    "# uids = test[uid]\n",
    "# out = pd.concat([uids, pd.Series(scores)], axis=1)\n",
    "# out[0] = out[0].apply(norm_score)\n",
    "# out.head()\n",
    "# out.to_csv('./model/predict.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### Distributions\n",
    "\n",
    "# # Final\n",
    "# sns.distplot(pred)\n",
    "# sns.distplot(scores)\n",
    "# plt.show()\n",
    "\n",
    "# meta_X = CLF.meta_X\n",
    "# meta_X.shape\n",
    "# meta_X[0]\n",
    "\n",
    "# # Base\n",
    "# for i in range(3):\n",
    "#     i\n",
    "#     sns.distplot(meta_X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############## Ana\n",
    "\n",
    "# base_models = [LGB, RF, XGB]\n",
    "# base_models_ = [list() for x in base_models]\n",
    "# kfold = KFold(n_splits=2, shuffle=True, random_state=123)\n",
    "\n",
    "# out_of_fold_predictions = np.zeros((X.shape[0], len(base_models)))\n",
    "# for i, model in enumerate(base_models):\n",
    "#     j = 0\n",
    "#     for train_index, valid_index in kfold.split(X, y):\n",
    "#         instance = clone(model)\n",
    "#         base_models_[i].append(instance)\n",
    "#         instance.fit(X.loc[train_index],  y.loc[train_index])\n",
    "#         len(X.loc[train_index])\n",
    "#         y_pred = instance.predict_proba(X.loc[valid_index])[:,1]\n",
    "#         ks = ks_score(y.loc[valid_index], y_pred)\n",
    "#         print(f'* KS({j}):{ks} *')\n",
    "#         out_of_fold_predictions[valid_index, i] = y_pred\n",
    "#         j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(out_of_fold_predictions)\n",
    "# len(out_of_fold_predictions[0])\n",
    "# out_of_fold_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_model = LR\n",
    "# meta_model_ = clone(meta_model)\n",
    "\n",
    "# meta_model_.fit(out_of_fold_predictions, y)\n",
    "# y_pred = meta_model_.predict_proba(out_of_fold_predictions)[:,1]\n",
    "# ks_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features = np.column_stack ([\n",
    "#     np.column_stack(\n",
    "#         [model.predict_proba(X)[:,1] for model in base_models]\n",
    "#     ).mean (axis=1)\n",
    "#     for base_models in base_models_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(meta_features)\n",
    "# len(meta_features[0])\n",
    "# meta_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features = pd.DataFrame()\n",
    "# for i, models_kfold in enumerate(base_models_):\n",
    "#     i\n",
    "#     prob_kfold = pd.DataFrame()\n",
    "#     for j, model in enumerate(models_kfold):\n",
    "#         j\n",
    "#         prob_kfold[j] = model.predict_proba(X)[:,1]\n",
    "#         prob_kfold.shape\n",
    "#     prob_kfold.head()\n",
    "#     meta_features[i] = prob_kfold.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_features.shape\n",
    "# meta_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' RF '''\n",
    "# RF.fit(meta_features, y)\n",
    "# ks_score(y, RF.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' RF1 '''\n",
    "# RF1 = RandomForestClassifier()\n",
    "# RF1.fit(meta_features, y)\n",
    "# ks_score(y, RF1.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' LGB '''\n",
    "# LGB.fit(meta_features, y)\n",
    "# ks_score(y, LGB.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' LR '''\n",
    "# LR.fit(meta_features, y)\n",
    "# ks_score(y, LR.predict_proba(meta_features)[:,1])\n",
    "\n",
    "# ''' MEAN '''\n",
    "# # LR.fit(meta_features, y)\n",
    "# ks_score(y, meta_features.mean(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
