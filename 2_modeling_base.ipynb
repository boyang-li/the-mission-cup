{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Meng/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats as spstats\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def get_time():\n",
    "    now = datetime.datetime.now().strftime(\"%m-%d %H:%M\")\n",
    "    print(now)\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Load '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 802)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Merge '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 802)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Split '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 801)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################  Load Features\n",
    "\n",
    "''' Load '''\n",
    "X = pd.read_csv('./tmp/train_d1234.csv', header=0, index_col=0)\n",
    "X.shape\n",
    "\n",
    "y = pd.read_csv('./data/train_label.csv', header=0, index_col=0)\n",
    "y.shape\n",
    "\n",
    "''' Merge '''\n",
    "# Merge\n",
    "xy = pd.merge(X, y, on=uid, how='inner')\n",
    "xy.drop(uid, axis=1, inplace=True)\n",
    "xy.shape\n",
    "\n",
    "''' Split '''\n",
    "# X, y\n",
    "X = xy.copy()\n",
    "y = X.pop(target)\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Grid Search\n",
    "\n",
    "scale_pos_weight = 119/21\n",
    "cv = 5\n",
    "\n",
    "param_general = {\n",
    "    'n_iter' : 50,\n",
    "    'cv' : cv, \n",
    "    'scoring' : 'roc_auc', \n",
    "    'n_jobs' : -1, \n",
    "    'random_state' : 123, \n",
    "    'verbose' : 1}\n",
    "\n",
    "# RF\n",
    "param_dist_rf = {\n",
    "    # Shape\n",
    "    'n_estimators' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_samples_split' : range(50, 100, 10),\n",
    "    'min_samples_leaf' : range(50, 100, 10),\n",
    "    # Sample\n",
    "    'class_weight' : ['balanced', None],\n",
    "    'max_features' : ['sqrt', 'log2'],\n",
    "    # Objective\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_dist_xgb = {\n",
    "    # Shape\n",
    "    'n_estimators' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'scale_pos_weight' : [scale_pos_weight, 1],\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bytree' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bylevel' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'eta' : np.linspace(0.01, 0.2, 20), # Learning_rate\n",
    "    'alpha' : np.linspace(0, 1, 10),\n",
    "    'lambda' : range(0, 50, 5),\n",
    "    'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "# XGBClassifier(alpha=0.7777777777777777, base_score=0.5, booster='gbtree',\n",
    "#               colsample_bylevel=0.7, colsample_bynode=1, colsample_bytree=0.6,\n",
    "#               early_stopping_rounds=10, eta=0.03, eval_metric='auc', gamma=0,\n",
    "#               lambda=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
    "#               min_child_weight=7, missing=None, n_estimatores=200,\n",
    "#               n_estimators=100, n_jobs=1, nthread=None,\n",
    "#               objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "#               reg_lambda=1, scale_pos_weight=1, seed=123, silent=1,\n",
    "#               subsample=0.8, verbose_eval=0, verbosity=1)\n",
    "\n",
    "# LGB\n",
    "param_dist_lgb = {\n",
    "    # Shape\n",
    "    'num_boost_round' : range(50, 500, 50),\n",
    "#     'num_boost_round' : range(50, 100, 10),\n",
    "    'num_leaves' : range(2**3, 2**10, 100),\n",
    "    'min_data_in_leaf' : range(50, 100, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'is_unbalance' : [True, False],\n",
    "    'bagging_freq': range(2, 10), # >0 enable bagging_fraction\n",
    "    'bagging_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'feature_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'learning_rate':np.linspace(0.01, 0.2, 20),    \n",
    "    'lambda_l1': np.linspace(0, 1, 10),\n",
    "    'lambda_l2': range(0, 50, 5),\n",
    "    'cat_smooth': range(1, 40, 5)\n",
    "#     'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "param_dist_lr = {\n",
    "    # Shape\n",
    "    'max_iter' : range(50, 500, 50),\n",
    "    # Sample\n",
    "    'class_weight' : [scale_pos_weight, 1],\n",
    "    # Algo\n",
    "    'solver' : ['sag', 'lbfgs', 'newton-cg'],\n",
    "    'C': [0.001, 0.01, 0.1] # 1/λ\n",
    "}\n",
    "\n",
    "##########\n",
    "\n",
    "# RF\n",
    "param_fixed_rf = {\n",
    "    'n_jobs' : -1,\n",
    "    'oob_score' : True,\n",
    "    'random_state':123,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_fixed_xgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'seed' : 123,\n",
    "    'silent' : 1,\n",
    "    'verbose_eval':0\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_fixed_lgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'metric' : 'auc',\n",
    "    'random_state' : 123,\n",
    "    'bagging_seed':123,\n",
    "    'feature_fraction_seed':123,\n",
    "    'verbose_eval' : 0\n",
    "}\n",
    "\n",
    "# LR\n",
    "param_fixed_lr = {\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 123,\n",
    "    'verbose' : 0     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=True, random_state=123, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9852"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 51.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 68.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=-1, oob_scor...\n",
       "                   param_distributions={'class_weight': ['balanced', None],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(3, 10),\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': range(50, 100, 10),\n",
       "                                        'min_samples_split': range(50, 100, 10),\n",
       "                                        'n_estimators': range(50, 500, 50)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7002853321328532"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:01\n"
     ]
    }
   ],
   "source": [
    "############## RF\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = RandomForestClassifier(**param_fixed_rf)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(RandomForestClassifier(**param_fixed_rf), param_dist_rf, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_rf.npy', best_params)\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "# \n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_rf}\n",
    "# model2 = RandomForestClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=123, silent=1,\n",
       "              subsample=1, verbose_eval=0, verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3422"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 160.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 220.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1,\n",
       "                                           eval_metric='auc', gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=-1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_...\n",
       "                                        'eta': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ]),\n",
       "                                        'lambda': range(0, 50, 5),\n",
       "                                        'max_depth': range(3, 10),\n",
       "                                        'min_child_weight': range(1, 9),\n",
       "                                        'n_estimatores': range(50, 500, 50),\n",
       "                                        'scale_pos_weight': [5.666666666666667,\n",
       "                                                             1],\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7251946138455383"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 15:55\n",
      "10-20 15:55\n"
     ]
    }
   ],
   "source": [
    "############## XGB\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = XGBClassifier(**param_fixed_xgb)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(XGBClassifier(**param_fixed_xgb), param_dist_xgb, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_xgb.npy', best_params)\n",
    "get_time()\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_xgb}\n",
    "# model2 = XGBClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_seed=123, boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=1.0, feature_fraction_seed=123,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               metric='auc', min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0, verbose_eval=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4274"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 69.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=LGBMClassifier(bagging_seed=123,\n",
       "                                            boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            feature_fraction_seed=123,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            metric='auc', min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leav...\n",
       "                                        'learning_rate': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ]),\n",
       "                                        'min_child_weight': range(1, 9),\n",
       "                                        'min_data_in_leaf': range(50, 100, 10),\n",
       "                                        'num_boost_round': range(50, 500, 50),\n",
       "                                        'num_leaves': range(8, 1024, 100),\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7294587094837935"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:13\n"
     ]
    }
   ],
   "source": [
    "############## LGB\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = LGBMClassifier(**param_fixed_lgb)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X) #, num_iteration=baseline.best_iteration_)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(LGBMClassifier(**param_fixed_lgb), param_dist_lgb, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_lgb.npy', best_params)\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_lgb}\n",
    "# model2 = LGBMClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 7)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ######## Tune Meta\n",
    "\n",
    "# X_meta = pd.read_csv('./tmp/meta_X.csv', header=0, index_col=0).values\n",
    "# poly = PolynomialFeatures(3, interaction_only=True)\n",
    "# X_meta = poly.fit_transform(X_meta)[:,1:]\n",
    "# X_meta.shape\n",
    "\n",
    "# y_meta = y.values\n",
    "\n",
    "# # LR\n",
    "# best_params_load = np.load('./model/base_lr.npy', allow_pickle=True).item()\n",
    "# model_params = {**best_params_load, **param_fixed_lr}\n",
    "# LR = LogisticRegression(**model_params)\n",
    "\n",
    "# # Tune\n",
    "#         ks = []\n",
    "#         meta_model = LR\n",
    "        \n",
    "#         kfold = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "#         j = 0\n",
    "#         meta_models_ = []\n",
    "#         for train_index, valid_index in kfold.split(X_meta, y_meta):\n",
    "#             instance = clone(meta_model)\n",
    "#             meta_models_.append(instance)\n",
    "#             instance.fit(X_meta[train_index],  y_meta[train_index])\n",
    "#             y_pred = instance.predict_proba(X_meta[valid_index])[:,1]\n",
    "#             ks.append(ks_score(y_meta[valid_index], y_pred))\n",
    "#             print(ks)\n",
    "#             j += 1\n",
    "#         pd.DataFrame(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 6)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=123, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3507"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   20.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='warn', n_jobs=-1,\n",
       "                                                penalty='l2', random_state=123,\n",
       "                                                solver='warn', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='warn', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.001, 0.01, 0.1],\n",
       "                                        'class_weight': [5.666666666666667, 1],\n",
       "                                        'max_iter': range(50, 500, 50),\n",
       "                                        'solver': ['sag', 'lbfgs',\n",
       "                                                   'newton-cg']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.735806162464986"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Test Clone Model '"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=1, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3503"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Test Save Params '"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=1, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3503"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## LR\n",
    "\n",
    "X_meta = pd.read_csv('./tmp/meta_X.csv', header=0, index_col=0).values\n",
    "poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "X_meta = poly.fit_transform(X_meta)\n",
    "X_meta.shape\n",
    "y_meta = y.values\n",
    "\n",
    "''' Baseline '''\n",
    "baseline = LogisticRegression(**param_fixed_lr)\n",
    "baseline.fit(X_meta, y)\n",
    "pred_baseline = baseline.predict_proba(X_meta)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(LogisticRegression(**param_fixed_lr), param_dist_lr, **param_general)\n",
    "grid.fit(X_meta, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_lr.npy', best_params)\n",
    "\n",
    "''' Test Clone Model '''\n",
    "model1 = grid.best_estimator_\n",
    "model1.fit(X_meta, y)\n",
    "ks_score(y, model1.predict_proba(X_meta)[:,1])\n",
    "\n",
    "''' Test Save Params '''\n",
    "best_params_load = np.load('./model/base_lr.npy', allow_pickle=True).item()\n",
    "model2_params = {**best_params_load, **param_fixed_lr}\n",
    "model2 = LogisticRegression(**model2_params)\n",
    "model2.fit(X_meta, y)\n",
    "ks_score(y, model2.predict_proba(X_meta)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=9, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=50,\n",
       "                       min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=400, n_jobs=-1, oob_score=True,\n",
       "                       random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>外部评分</td>\n",
       "      <td>0.050332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>工作日期距申请日期天数</td>\n",
       "      <td>0.038235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>工作日期距申请日期月数</td>\n",
       "      <td>0.037403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>出生日期距申请日期天数</td>\n",
       "      <td>0.026822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>最近一次换手机号码距申请日天数</td>\n",
       "      <td>0.016098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature        rf\n",
       "0             外部评分  0.050332\n",
       "1      工作日期距申请日期天数  0.038235\n",
       "2      工作日期距申请日期月数  0.037403\n",
       "3      出生日期距申请日期天数  0.026822\n",
       "4  最近一次换手机号码距申请日天数  0.016098"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################ Important Features\n",
    "\n",
    "######## RF\n",
    "\n",
    "best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_rf}\n",
    "RF = RandomForestClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "RF.fit(X, y)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(RF.feature_importances_, columns=['rf'])\n",
    "fscore_rf = pd.concat([f, score], axis=1).sort_values(by='rf', ascending=False).reset_index(drop=True)\n",
    "fscore_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.7777777777777777, base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=0.7, colsample_bynode=1, colsample_bytree=0.6,\n",
       "              early_stopping_rounds=10, eta=0.03, eval_metric='auc', gamma=0,\n",
       "              lambda=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=7, missing=None, n_estimatores=200,\n",
       "              n_estimators=100, n_jobs=-1, nthread=None,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=123, silent=1,\n",
       "              subsample=0.8, verbose_eval=0, verbosity=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>教育程度_4</td>\n",
       "      <td>0.012084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>教育程度_1</td>\n",
       "      <td>0.011669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>信用额度sum比_d</td>\n",
       "      <td>0.010624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>工作日期距申请日期月数</td>\n",
       "      <td>0.008683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>商品类别_27mean_y</td>\n",
       "      <td>0.008052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature       xgb\n",
       "0         教育程度_4  0.012084\n",
       "1         教育程度_1  0.011669\n",
       "2     信用额度sum比_d  0.010624\n",
       "3    工作日期距申请日期月数  0.008683\n",
       "4  商品类别_27mean_y  0.008052"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# XGB importance\n",
    "\n",
    "# XGB\n",
    "best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_xgb}\n",
    "XGB = XGBClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "XGB.fit(X, y)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(XGB.feature_importances_, columns=['xgb'])\n",
    "fscore_xgb = pd.concat([f, score], axis=1).sort_values(by='xgb', ascending=False).reset_index(drop=True)\n",
    "fscore_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, bagging_seed=123,\n",
       "               boosting_type='gbdt', cat_smooth=16, class_weight=None,\n",
       "               colsample_bytree=1.0, feature_fraction=0.9,\n",
       "               feature_fraction_seed=123, importance_type='split',\n",
       "               is_unbalance=True, lambda_l1=0.8888888888888888, lambda_l2=25,\n",
       "               learning_rate=0.02, max_depth=-1, metric='auc',\n",
       "               min_child_samples=20, min_child_weight=2, min_data_in_leaf=90,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "               num_boost_round=400, num_leaves=308, objective=None,\n",
       "               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=0.8, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>出生日期距申请日期天数</td>\n",
       "      <td>3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>贷款年金</td>\n",
       "      <td>2969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>信用额度</td>\n",
       "      <td>2801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>身份认证日期距申请日期天数</td>\n",
       "      <td>2330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>居住地人口密集度</td>\n",
       "      <td>2261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature   lgb\n",
       "0    出生日期距申请日期天数  3127\n",
       "1           贷款年金  2969\n",
       "2           信用额度  2801\n",
       "3  身份认证日期距申请日期天数  2330\n",
       "4       居住地人口密集度  2261"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# LGB importance\n",
    "\n",
    "# LGB\n",
    "best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lgb}\n",
    "LGB = LGBMClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "LGB.fit(X, y)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(LGB.feature_importances_, columns=['lgb'])\n",
    "fscore_lgb = pd.concat([f, score], axis=1).sort_values(by='lgb', ascending=False).reset_index(drop=True)\n",
    "fscore_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>外部评分</td>\n",
       "      <td>0.131480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>工作日期距申请日期月数</td>\n",
       "      <td>0.105619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>工作日期距申请日期天数</td>\n",
       "      <td>0.105490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>出生日期距申请日期天数</td>\n",
       "      <td>0.103297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>拟申请拒绝率_d</td>\n",
       "      <td>0.102523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature      corr\n",
       "0         外部评分  0.131480\n",
       "1  工作日期距申请日期月数  0.105619\n",
       "2  工作日期距申请日期天数  0.105490\n",
       "3  出生日期距申请日期天数  0.103297\n",
       "4     拟申请拒绝率_d  0.102523"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# correlations\n",
    "\n",
    "correlations = xy.corr()\n",
    "\n",
    "# Save\n",
    "correlations.apply(abs).to_csv('./ana/0_correlations_abs.csv')\n",
    "correlations.to_csv('./ana/0_correlations.csv')\n",
    "\n",
    "# Abs\n",
    "correlations_target_abs = correlations.loc[correlations.index != target, target].apply(abs).sort_values(ascending=False)\n",
    "\n",
    "f = pd.DataFrame(correlations_target_abs.index, columns=['feature'])\n",
    "score_corr = pd.DataFrame(correlations_target_abs.values, columns=['corr'])\n",
    "fscore_corr = pd.concat([f, score_corr], axis=1).sort_values(by='corr', ascending=False).reset_index(drop=True)\n",
    "fscore_corr.head()\n",
    "\n",
    "\n",
    "# # >=0.01\n",
    "# features_top = {}\n",
    "# features_top['corr'] = correlations_target_abs[correlations_target_abs>=0.01]\n",
    "# features_top['corr'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>corr</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lgb</th>\n",
       "      <th>corr_rank</th>\n",
       "      <th>rf_rank</th>\n",
       "      <th>xgb_rank</th>\n",
       "      <th>lgb_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>外部评分</td>\n",
       "      <td>0.131480</td>\n",
       "      <td>0.050332</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>1938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>工作日期距申请日期月数</td>\n",
       "      <td>0.105619</td>\n",
       "      <td>0.037403</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>927</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>工作日期距申请日期天数</td>\n",
       "      <td>0.105490</td>\n",
       "      <td>0.038235</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>1911</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>出生日期距申请日期天数</td>\n",
       "      <td>0.103297</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>3127</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>拟申请拒绝率_d</td>\n",
       "      <td>0.102523</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.002846</td>\n",
       "      <td>140</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature      corr        rf       xgb   lgb  corr_rank  rf_rank  \\\n",
       "0         外部评分  0.131480  0.050332  0.006847  1938        1.0      1.0   \n",
       "1  工作日期距申请日期月数  0.105619  0.037403  0.008683   927        2.0      3.0   \n",
       "2  工作日期距申请日期天数  0.105490  0.038235  0.004481  1911        3.0      2.0   \n",
       "3  出生日期距申请日期天数  0.103297  0.026822  0.004071  3127        4.0      4.0   \n",
       "4     拟申请拒绝率_d  0.102523  0.009344  0.002846   140        5.0     18.0   \n",
       "\n",
       "   xgb_rank  lgb_rank  \n",
       "0       8.0       8.0  \n",
       "1       4.0      40.0  \n",
       "2      21.0       9.0  \n",
       "3      26.0       1.0  \n",
       "4      61.0     172.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Describe '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>7.910000e+02</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>2.315137e-02</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>153.308365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.405697e-02</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>368.523305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.216878e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>4.085393e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.306164e-02</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.614999e-02</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.314799e-01</td>\n",
       "      <td>0.050332</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>3127.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corr          rf         xgb          lgb\n",
       "count  7.910000e+02  801.000000  801.000000   801.000000\n",
       "mean   2.315137e-02    0.001248    0.001248   153.308365\n",
       "std    2.405697e-02    0.003464    0.001424   368.523305\n",
       "min    1.216878e-15    0.000000    0.000000     0.000000\n",
       "25%    4.085393e-03    0.000000    0.000000     0.000000\n",
       "50%    1.306164e-02    0.000130    0.001337    12.000000\n",
       "75%    3.614999e-02    0.000892    0.001933   109.000000\n",
       "max    1.314799e-01    0.050332    0.012084  3127.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Merge important\n",
    "\n",
    "fscore = pd.merge(fscore_corr, fscore_rf, on='feature')\n",
    "fscore = pd.merge(fscore, fscore_xgb, on='feature')\n",
    "fscore = pd.merge(fscore, fscore_lgb, on='feature')\n",
    "# Add rank\n",
    "frank = fscore.rank(numeric_only=True, method='min', ascending=False)\n",
    "fscore = pd.merge(fscore, frank, left_index=True, right_index=True, suffixes=['', '_rank'])\n",
    "\n",
    "fscore.shape\n",
    "fscore.head()\n",
    "fscore.to_csv('./model/f_score.csv')\n",
    "\n",
    "''' Describe '''\n",
    "fscore[['corr', 'rf', 'xgb', 'lgb']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Corr '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt_corr</th>\n",
       "      <th>cnt_rf</th>\n",
       "      <th>cnt_xgb</th>\n",
       "      <th>cnt_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Count</td>\n",
       "      <td>791</td>\n",
       "      <td>801</td>\n",
       "      <td>801</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cnt_corr  cnt_rf  cnt_xgb  cnt_lgb\n",
       "Count       791     801      801      801"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr_corr</th>\n",
       "      <th>corr_rf</th>\n",
       "      <th>corr_xgb</th>\n",
       "      <th>corr_lgb</th>\n",
       "      <th>rf_xgb</th>\n",
       "      <th>xgb_rf</th>\n",
       "      <th>rf_lgb</th>\n",
       "      <th>lgb_rf</th>\n",
       "      <th>xgb_lgb</th>\n",
       "      <th>lgb_xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Intersection</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              corr_corr  corr_rf  corr_xgb  corr_lgb  rf_xgb  xgb_rf  rf_lgb  \\\n",
       "Intersection        1.0      1.0       1.0       1.0     1.0     1.0     1.0   \n",
       "\n",
       "              lgb_rf  xgb_lgb  lgb_xgb  \n",
       "Intersection     1.0      1.0      1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' all VS corr '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' top_f_final '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Intersection by Score\n",
    "\n",
    "# By score\n",
    "# th_imp = {'corr':0.01, 'rf':0.002, 'xgb':0.003, 'lgb':5} # 404\n",
    "# th_imp = {'corr':0.01, 'rf':0.0005, 'xgb':0.0015, 'lgb':5} # 518\t318\t397\n",
    "th_imp = {'corr':0, 'rf':0, 'xgb':0, 'lgb':0} \n",
    "\n",
    "top_f = {}\n",
    "cnt_f = {}\n",
    "inter_cnt = {}\n",
    "for k in 'corr', 'rf', 'xgb', 'lgb':\n",
    "    # top\n",
    "    t = fscore.loc[fscore[f'{k}']>=th_imp[k], 'feature']\n",
    "    top_f[k] = set(t) # set\n",
    "    # len\n",
    "    cnt_f[f'cnt_{k}'] = len(t)\n",
    "    # intersection with Corr\n",
    "    inter_cnt[f'corr_{k}'] = round(len(top_f['corr'].intersection(top_f[k]))/len(top_f['corr']), 2)\n",
    "\n",
    "# Intersection\n",
    "inter_cnt['rf_xgb'] = round(len(top_f['rf'].intersection(top_f['xgb']))/len(top_f['rf']), 2)\n",
    "inter_cnt['xgb_rf'] = round(len(top_f['rf'].intersection(top_f['xgb']))/len(top_f['xgb']), 2)\n",
    "inter_cnt['rf_lgb'] = round(len(top_f['rf'].intersection(top_f['lgb']))/len(top_f['rf']), 2)\n",
    "inter_cnt['lgb_rf'] = round(len(top_f['rf'].intersection(top_f['lgb']))/len(top_f['lgb']), 2)\n",
    "inter_cnt['xgb_lgb'] = round(len(top_f['xgb'].intersection(top_f['lgb']))/len(top_f['xgb']), 2)\n",
    "inter_cnt['lgb_xgb'] = round(len(top_f['xgb'].intersection(top_f['lgb']))/len(top_f['lgb']), 2)\n",
    "\n",
    "''' Corr '''\n",
    "pd.DataFrame(cnt_f, index=['Count'])\n",
    "pd.DataFrame(inter_cnt, index=['Intersection'])\n",
    "\n",
    "''' all VS corr '''\n",
    "top = {}\n",
    "top['all'] = top_f['rf'].union(top_f['xgb']).union(top_f['lgb'])\n",
    "diff = top_f['corr'].difference(top['all'])\n",
    "len(diff)\n",
    "# diff\n",
    "\n",
    "### Save\n",
    "# + diff\n",
    "''' top_f_final ''' \n",
    "top_f_final = {} # 入模特征列表\n",
    "for k in 'rf', 'xgb', 'lgb':\n",
    "    top_f_final[k] = top_f[k].union(diff) # 保存特征列表\n",
    "    len(top_f_final[k])\n",
    "np.save('./model/base_features.npy', top_f_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'x0 x25',\n",
       " 'x1 x2',\n",
       " 'x10 x13',\n",
       " 'x10 x23',\n",
       " 'x13 x16',\n",
       " 'x13 x17',\n",
       " 'x13 x18',\n",
       " 'x13 x20',\n",
       " 'x13 x22',\n",
       " 'x13 x23',\n",
       " 'x13^2',\n",
       " 'x15 x25',\n",
       " 'x15 x27',\n",
       " 'x22 x23',\n",
       " 'x24 x25',\n",
       " 'x25 x27',\n",
       " 'x3 x20',\n",
       " 'x4 x13',\n",
       " 'x4 x23',\n",
       " 'x9 x25',\n",
       " '信用比申请额度',\n",
       " '分期付款实际支付时间max',\n",
       " '历史贷款授信距本次申请时间max',\n",
       " '外部评分',\n",
       " '客户收入',\n",
       " '拟实际应还贷款金额max',\n",
       " '本期贷款金额min',\n",
       " '本期还款金额meansumsum',\n",
       " '贷款年金max',\n",
       " '贷款年金mean'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### Polynomial\n",
    "\n",
    "m = 50 # 交集\n",
    "n = 10 # 合集\n",
    "\n",
    "top_f_inters = set(fscore.loc[(fscore['corr_rank'] <= m) & \n",
    "                          (fscore['rf_rank'] <= m) & \n",
    "                          (fscore['xgb_rank'] <= m) & \n",
    "                          (fscore['lgb_rank'] <= m), 'feature'])\n",
    "len(top_f_inters)\n",
    "top_f_union = set(fscore.loc[(fscore['corr_rank'] <= n) | \n",
    "                          (fscore['rf_rank'] <= n) | \n",
    "                          (fscore['xgb_rank'] <= n) | \n",
    "                          (fscore['lgb_rank'] <= n), 'feature'])\n",
    "len(top_f_union)\n",
    "top_poly = top_f_inters.union(top_f_union)\n",
    "len(top_poly)\n",
    "top_poly\n",
    "\n",
    "np.save('./tmp/0_feats_poly.npy', top_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>corr</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lgb</th>\n",
       "      <th>corr_rank</th>\n",
       "      <th>rf_rank</th>\n",
       "      <th>xgb_rank</th>\n",
       "      <th>lgb_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>信用额度sum比</td>\n",
       "      <td>0.060161</td>\n",
       "      <td>0.021362</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>435</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>申请额度sum比</td>\n",
       "      <td>0.058850</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>446</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>87.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>贷款年金sum比</td>\n",
       "      <td>0.055172</td>\n",
       "      <td>0.020973</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>669</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>信用比申请额度</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>0.018592</td>\n",
       "      <td>0.005270</td>\n",
       "      <td>1811</td>\n",
       "      <td>246.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>信用额度比mean</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>0.009943</td>\n",
       "      <td>0.003257</td>\n",
       "      <td>1208</td>\n",
       "      <td>254.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>信用额度比min</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.015734</td>\n",
       "      <td>0.006934</td>\n",
       "      <td>1154</td>\n",
       "      <td>264.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265</td>\n",
       "      <td>信用额度比max</td>\n",
       "      <td>0.006311</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>1322</td>\n",
       "      <td>266.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>366</td>\n",
       "      <td>本期还款金额ms比贷款金额ssmean</td>\n",
       "      <td>0.001326</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>1602</td>\n",
       "      <td>367.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 feature      corr        rf       xgb   lgb  corr_rank  \\\n",
       "16              信用额度sum比  0.060161  0.021362  0.005245   435       17.0   \n",
       "17              申请额度sum比  0.058850  0.017807  0.005849   446       18.0   \n",
       "22              贷款年金sum比  0.055172  0.020973  0.006353   669       23.0   \n",
       "245              信用比申请额度  0.007562  0.018592  0.005270  1811      246.0   \n",
       "253            信用额度比mean  0.006856  0.009943  0.003257  1208      254.0   \n",
       "263             信用额度比min  0.006422  0.015734  0.006934  1154      264.0   \n",
       "265             信用额度比max  0.006311  0.007665  0.003631  1322      266.0   \n",
       "366  本期还款金额ms比贷款金额ssmean  0.001326  0.019778  0.005696  1602      367.0   \n",
       "\n",
       "     rf_rank  xgb_rank  lgb_rank  \n",
       "16       5.0      30.0      90.0  \n",
       "17      14.0      22.0      87.0  \n",
       "22       6.0      20.0      58.0  \n",
       "245     12.0      28.0      12.0  \n",
       "253     25.0     122.0      27.0  \n",
       "263     15.0      15.0      31.0  \n",
       "265     39.0      89.0      22.0  \n",
       "366      9.0      24.0      14.0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fscore.loc[fscore['feature'].str.contains('比'), :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
