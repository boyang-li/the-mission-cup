{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def get_time():\n",
    "    now = datetime.datetime.now().strftime(\"%m-%d %H:%M\")\n",
    "    print(now)\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "140000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Load\n",
    "\n",
    "# X = pd.read_csv('./tmp/1_X.csv', header=0, index_col=0)\n",
    "# X.shape\n",
    "# X.head()\n",
    "\n",
    "# y = pd.read_csv('./tmp/1_y.csv', header=0, index_col=0)\n",
    "# y.shape\n",
    "# y.head()\n",
    "\n",
    "X = pd.read_csv('./tmp/train_d12_d3_dum.csv', header=0, index_col=0).drop(uid, axis=1).values\n",
    "# X = pd.read_csv('./tmp/1_X.csv', header=0, index_col=0).values\n",
    "len(X)\n",
    "len(X[0])\n",
    "\n",
    "y = pd.read_csv('./tmp/1_y.csv', header=0, index_col=0)['0'].values\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Grid Search\n",
    "\n",
    "scale_pos_weight = 119/21\n",
    "\n",
    "param_general = {\n",
    "#     'n_iter' : 100,\n",
    "#     'cv' : 5, \n",
    "    'n_iter' : 50,\n",
    "    'cv' : 5, \n",
    "    'scoring' : 'roc_auc', \n",
    "    'n_jobs' : -1, \n",
    "    'random_state' : 123, \n",
    "    'verbose' : 1}\n",
    "\n",
    "# RF\n",
    "param_dist_rf = {\n",
    "    # Shape\n",
    "    'n_estimators' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_samples_split' : range(50, 100, 10),\n",
    "    'min_samples_leaf' : range(50, 100, 10),\n",
    "    # Sample\n",
    "    'class_weight' : ['balanced', None],\n",
    "    'max_features' : ['sqrt', 'log2'],\n",
    "    # Objective\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_dist_xgb = {\n",
    "    # Shape\n",
    "    'n_estimatores' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'scale_pos_weight' : [scale_pos_weight, 1],\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bytree' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bylevel' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'eta' : np.linspace(0.01, 0.2, 20), # Learning_rate\n",
    "    'alpha' : np.linspace(0, 1, 10),\n",
    "    'lambda' : range(0, 50, 5),\n",
    "    'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_dist_lgb = {\n",
    "    # Shape\n",
    "    'num_boost_round' : range(50, 500, 50),\n",
    "#     'num_boost_round' : range(50, 100, 10),\n",
    "    'num_leaves' : range(2**3, 2**10, 100),\n",
    "    'min_data_in_leaf' : range(50, 100, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'is_unbalance' : [True, False],\n",
    "    'bagging_freq': range(2, 10), # >0 enable bagging_fraction\n",
    "    'bagging_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'feature_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'learning_rate':np.linspace(0.01, 0.2, 20),    \n",
    "    'lambda_l1': np.linspace(0, 1, 10),\n",
    "    'lambda_l2': range(0, 50, 5),\n",
    "    'cat_smooth': range(1, 40, 5)\n",
    "#     'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "##########\n",
    "\n",
    "# RF\n",
    "param_fixed_rf = {\n",
    "    'n_jobs' : -1,\n",
    "    'oob_score' : True,\n",
    "    'random_state':123,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_fixed_xgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'seed' : 123,\n",
    "    'silent' : 1,\n",
    "    'verbose_eval':0\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_fixed_lgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'metric' : 'auc',\n",
    "    'bagging_seed':123,\n",
    "    'feature_fraction_seed':123,\n",
    "    'verbose_eval' : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=True, random_state=123, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9852"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "############## RF\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = RandomForestClassifier(**param_fixed_rf)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(RandomForestClassifier(**param_fixed_rf), param_dist_rf, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_rf.npy', best_params)\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "# \n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_rf}\n",
    "# model2 = RandomForestClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## XGB\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = XGBClassifier(**param_fixed_xgb)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(XGBClassifier(**param_fixed_xgb), param_dist_xgb, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_xgb.npy', best_params)\n",
    "get_time()\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_xgb}\n",
    "# model2 = XGBClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## LGB\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = LGBMClassifier(**param_fixed_lgb)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X) #, num_iteration=baseline.best_iteration_)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(LGBMClassifier(**param_fixed_lgb), param_dist_lgb, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_lgb.npy', best_params)\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_lgb}\n",
    "# model2 = LGBMClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
