{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def get_time():\n",
    "    now = datetime.datetime.now().strftime(\"%m-%d %H:%M\")\n",
    "    print(now)\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Load '"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 405)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 1)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Merge '"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 405)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Split '"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 404)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################  Load Features\n",
    "\n",
    "''' Load '''\n",
    "X = pd.read_csv('./tmp/train_d1234.csv', header=0, index_col=0)\n",
    "X.shape\n",
    "\n",
    "y = pd.read_csv('./data/train_label.csv', header=0, index_col=0)\n",
    "y.shape\n",
    "\n",
    "''' Merge '''\n",
    "# Merge\n",
    "xy = pd.merge(X, y, on=uid, how='inner')\n",
    "xy.drop(uid, axis=1, inplace=True)\n",
    "xy.shape\n",
    "\n",
    "''' Split '''\n",
    "# X, y\n",
    "X = xy.copy()\n",
    "y = X.pop(target)\n",
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Grid Search\n",
    "\n",
    "scale_pos_weight = 119/21\n",
    "cv = 5\n",
    "\n",
    "param_general = {\n",
    "    'n_iter' : 50,\n",
    "    'cv' : cv, \n",
    "    'scoring' : 'roc_auc', \n",
    "    'n_jobs' : -1, \n",
    "    'random_state' : 123, \n",
    "    'verbose' : 1}\n",
    "\n",
    "# RF\n",
    "param_dist_rf = {\n",
    "    # Shape\n",
    "    'n_estimators' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_samples_split' : range(50, 100, 10),\n",
    "    'min_samples_leaf' : range(50, 100, 10),\n",
    "    # Sample\n",
    "    'class_weight' : ['balanced', None],\n",
    "    'max_features' : ['sqrt', 'log2'],\n",
    "    # Objective\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_dist_xgb = {\n",
    "    # Shape\n",
    "    'n_estimators' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'scale_pos_weight' : [scale_pos_weight, 1],\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bytree' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bylevel' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'eta' : np.linspace(0.01, 0.2, 20), # Learning_rate\n",
    "    'alpha' : np.linspace(0, 1, 10),\n",
    "    'lambda' : range(0, 50, 5),\n",
    "    'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "# XGBClassifier(alpha=0.7777777777777777, base_score=0.5, booster='gbtree',\n",
    "#               colsample_bylevel=0.7, colsample_bynode=1, colsample_bytree=0.6,\n",
    "#               early_stopping_rounds=10, eta=0.03, eval_metric='auc', gamma=0,\n",
    "#               lambda=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
    "#               min_child_weight=7, missing=None, n_estimatores=200,\n",
    "#               n_estimators=100, n_jobs=1, nthread=None,\n",
    "#               objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "#               reg_lambda=1, scale_pos_weight=1, seed=123, silent=1,\n",
    "#               subsample=0.8, verbose_eval=0, verbosity=1)\n",
    "\n",
    "# LGB\n",
    "param_dist_lgb = {\n",
    "    # Shape\n",
    "    'num_boost_round' : range(50, 500, 50),\n",
    "#     'num_boost_round' : range(50, 100, 10),\n",
    "    'num_leaves' : range(2**3, 2**10, 100),\n",
    "    'min_data_in_leaf' : range(50, 100, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'is_unbalance' : [True, False],\n",
    "    'bagging_freq': range(2, 10), # >0 enable bagging_fraction\n",
    "    'bagging_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'feature_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'learning_rate':np.linspace(0.01, 0.2, 20),    \n",
    "    'lambda_l1': np.linspace(0, 1, 10),\n",
    "    'lambda_l2': range(0, 50, 5),\n",
    "    'cat_smooth': range(1, 40, 5)\n",
    "#     'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "param_dist_lr = {\n",
    "    # Shape\n",
    "    'max_iter' : range(50, 500, 50),\n",
    "    # Sample\n",
    "    'class_weight' : [scale_pos_weight, 1],\n",
    "    # Algo\n",
    "    'solver' : ['sag', 'lbfgs', 'newton-cg'],\n",
    "    'C': [0.001, 0.01, 0.1, 1] # 1/λ\n",
    "}\n",
    "\n",
    "##########\n",
    "\n",
    "# RF\n",
    "param_fixed_rf = {\n",
    "    'n_jobs' : -1,\n",
    "    'oob_score' : True,\n",
    "    'random_state':123,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_fixed_xgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'seed' : 123,\n",
    "    'silent' : 1,\n",
    "    'verbose_eval':0\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_fixed_lgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'metric' : 'auc',\n",
    "    'random_state' : 123,\n",
    "    'bagging_seed':123,\n",
    "    'feature_fraction_seed':123,\n",
    "    'verbose_eval' : 0\n",
    "}\n",
    "\n",
    "# LR\n",
    "param_fixed_lr = {\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 123,\n",
    "    'verbose' : 0     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=True, random_state=123, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9852"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 51.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 68.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=-1, oob_scor...\n",
       "                   param_distributions={'class_weight': ['balanced', None],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(3, 10),\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': range(50, 100, 10),\n",
       "                                        'min_samples_split': range(50, 100, 10),\n",
       "                                        'n_estimators': range(50, 500, 50)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7002853321328532"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:01\n"
     ]
    }
   ],
   "source": [
    "############## RF\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = RandomForestClassifier(**param_fixed_rf)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(RandomForestClassifier(**param_fixed_rf), param_dist_rf, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_rf.npy', best_params)\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "# \n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_rf}\n",
    "# model2 = RandomForestClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=123, silent=1,\n",
       "              subsample=1, verbose_eval=0, verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3422"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 160.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 220.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1,\n",
       "                                           eval_metric='auc', gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=-1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_...\n",
       "                                        'eta': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ]),\n",
       "                                        'lambda': range(0, 50, 5),\n",
       "                                        'max_depth': range(3, 10),\n",
       "                                        'min_child_weight': range(1, 9),\n",
       "                                        'n_estimatores': range(50, 500, 50),\n",
       "                                        'scale_pos_weight': [5.666666666666667,\n",
       "                                                             1],\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7251946138455383"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 15:55\n",
      "10-20 15:55\n"
     ]
    }
   ],
   "source": [
    "############## XGB\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = XGBClassifier(**param_fixed_xgb)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(XGBClassifier(**param_fixed_xgb), param_dist_xgb, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_xgb.npy', best_params)\n",
    "get_time()\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_xgb}\n",
    "# model2 = XGBClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "外部评分_x    66440.027278\n",
       "外部评分_y    66440.027278\n",
       "dtype: float64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[X.columns[X.columns.str.startswith('外部评分')]].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_seed=123, boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=1.0, feature_fraction_seed=123,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               metric='auc', min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0, verbose_eval=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4274"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 69.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=LGBMClassifier(bagging_seed=123,\n",
       "                                            boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            feature_fraction_seed=123,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            metric='auc', min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leav...\n",
       "                                        'learning_rate': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ]),\n",
       "                                        'min_child_weight': range(1, 9),\n",
       "                                        'min_data_in_leaf': range(50, 100, 10),\n",
       "                                        'num_boost_round': range(50, 500, 50),\n",
       "                                        'num_leaves': range(8, 1024, 100),\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7294587094837935"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:13\n"
     ]
    }
   ],
   "source": [
    "############## LGB\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = LGBMClassifier(**param_fixed_lgb)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X) #, num_iteration=baseline.best_iteration_)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(LGBMClassifier(**param_fixed_lgb), param_dist_lgb, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_lgb.npy', best_params)\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_lgb}\n",
    "# model2 = LGBMClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 3)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=123, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3503"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   20.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='warn', n_jobs=-1,\n",
       "                                                penalty='l2', random_state=123,\n",
       "                                                solver='warn', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='warn', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.001, 0.01, 0.1, 1],\n",
       "                                        'class_weight': [5.666666666666667, 1],\n",
       "                                        'max_iter': range(50, 500, 50),\n",
       "                                        'solver': ['sag', 'lbfgs',\n",
       "                                                   'newton-cg']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7358445518207283"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Test Clone Model '"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=1, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=50,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=123, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3504"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Test Save Params '"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=1, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=50,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=123, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3504"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## LR\n",
    "\n",
    "X_meta = pd.read_csv('./tmp/meta_X.csv', header=0, index_col=0)\n",
    "X_meta.shape\n",
    "y.shape\n",
    "\n",
    "''' Baseline '''\n",
    "baseline = LogisticRegression(**param_fixed_lr)\n",
    "baseline.fit(X_meta, y)\n",
    "pred_baseline = baseline.predict_proba(X_meta)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(LogisticRegression(**param_fixed_lr), param_dist_lr, **param_general)\n",
    "grid.fit(X_meta, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_lr.npy', best_params)\n",
    "\n",
    "''' Test Clone Model '''\n",
    "model1 = grid.best_estimator_\n",
    "model1.fit(X_meta, y)\n",
    "ks_score(y, model1.predict_proba(X_meta)[:,1])\n",
    "\n",
    "''' Test Save Params '''\n",
    "best_params_load = np.load('./model/base_lr.npy', allow_pickle=True).item()\n",
    "model2_params = {**best_params_load, **param_fixed_lr}\n",
    "model2 = LogisticRegression(**model2_params)\n",
    "model2.fit(X_meta, y)\n",
    "ks_score(y, model2.predict_proba(X_meta)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=9, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=50,\n",
       "                       min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=400, n_jobs=-1, oob_score=True,\n",
       "                       random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>外部评分</td>\n",
       "      <td>0.069753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>出生日期距申请日期天数</td>\n",
       "      <td>0.045533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>工作日期距申请日期天数</td>\n",
       "      <td>0.033629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>教育程度</td>\n",
       "      <td>0.026104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>信用额度sum比</td>\n",
       "      <td>0.021362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature        rf\n",
       "0         外部评分  0.069753\n",
       "1  出生日期距申请日期天数  0.045533\n",
       "2  工作日期距申请日期天数  0.033629\n",
       "3         教育程度  0.026104\n",
       "4     信用额度sum比  0.021362"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################ Important Features\n",
    "\n",
    "######## RF\n",
    "\n",
    "best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_rf}\n",
    "RF = RandomForestClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "RF.fit(X, y)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(RF.feature_importances_, columns=['rf'])\n",
    "fscore_rf = pd.concat([f, score], axis=1).sort_values(by='rf', ascending=False).reset_index(drop=True)\n",
    "fscore_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.7777777777777777, base_score=0.5, booster='gbtree',\n",
       "              colsample_bylevel=0.7, colsample_bynode=1, colsample_bytree=0.6,\n",
       "              early_stopping_rounds=10, eta=0.03, eval_metric='auc', gamma=0,\n",
       "              lambda=0, learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=7, missing=None, n_estimatores=200,\n",
       "              n_estimators=100, n_jobs=-1, nthread=None,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=123, silent=1,\n",
       "              subsample=0.8, verbose_eval=0, verbosity=1)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>xgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>教育程度</td>\n",
       "      <td>0.018646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>客户类型_0sum</td>\n",
       "      <td>0.014576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>收入类型</td>\n",
       "      <td>0.013740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>外部评分</td>\n",
       "      <td>0.012082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>客户居住地评分2</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature       xgb\n",
       "0       教育程度  0.018646\n",
       "1  客户类型_0sum  0.014576\n",
       "2       收入类型  0.013740\n",
       "3       外部评分  0.012082\n",
       "4   客户居住地评分2  0.011659"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# XGB importance\n",
    "\n",
    "# XGB\n",
    "best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_xgb}\n",
    "XGB = XGBClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "XGB.fit(X, y)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(XGB.feature_importances_, columns=['xgb'])\n",
    "fscore_xgb = pd.concat([f, score], axis=1).sort_values(by='xgb', ascending=False).reset_index(drop=True)\n",
    "fscore_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, bagging_seed=123,\n",
       "               boosting_type='gbdt', cat_smooth=16, class_weight=None,\n",
       "               colsample_bytree=1.0, feature_fraction=0.9,\n",
       "               feature_fraction_seed=123, importance_type='split',\n",
       "               is_unbalance=True, lambda_l1=0.8888888888888888, lambda_l2=25,\n",
       "               learning_rate=0.02, max_depth=-1, metric='auc',\n",
       "               min_child_samples=20, min_child_weight=2, min_data_in_leaf=90,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "               num_boost_round=400, num_leaves=308, objective=None,\n",
       "               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=0.8, ...)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>贷款年金</td>\n",
       "      <td>3160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>出生日期距申请日期天数</td>\n",
       "      <td>3073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>身份认证日期距申请日期天数</td>\n",
       "      <td>3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>信用额度</td>\n",
       "      <td>2918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>工作日期距申请日期天数</td>\n",
       "      <td>2840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature   lgb\n",
       "0           贷款年金  3160\n",
       "1    出生日期距申请日期天数  3073\n",
       "2  身份认证日期距申请日期天数  3006\n",
       "3           信用额度  2918\n",
       "4    工作日期距申请日期天数  2840"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# LGB importance\n",
    "\n",
    "# LGB\n",
    "best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lgb}\n",
    "LGB = LGBMClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "LGB.fit(X, y)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(LGB.feature_importances_, columns=['lgb'])\n",
    "fscore_lgb = pd.concat([f, score], axis=1).sort_values(by='lgb', ascending=False).reset_index(drop=True)\n",
    "fscore_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>外部评分</td>\n",
       "      <td>0.131480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>出生日期距申请日期天数</td>\n",
       "      <td>0.103142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>客户居住地评分2</td>\n",
       "      <td>0.078824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>客户居住地评分1</td>\n",
       "      <td>0.076496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>最近一次换手机号码距申请日天数</td>\n",
       "      <td>0.074596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature      corr\n",
       "0             外部评分  0.131480\n",
       "1      出生日期距申请日期天数  0.103142\n",
       "2         客户居住地评分2  0.078824\n",
       "3         客户居住地评分1  0.076496\n",
       "4  最近一次换手机号码距申请日天数  0.074596"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# correlations\n",
    "\n",
    "correlations = xy.corr()\n",
    "\n",
    "# Save\n",
    "correlations.apply(abs).to_csv('./ana/0_correlations_abs.csv')\n",
    "correlations.to_csv('./ana/0_correlations.csv')\n",
    "\n",
    "# Abs\n",
    "correlations_target_abs = correlations.loc[correlations.index != target, target].apply(abs).sort_values(ascending=False)\n",
    "\n",
    "f = pd.DataFrame(correlations_target_abs.index, columns=['feature'])\n",
    "score_corr = pd.DataFrame(correlations_target_abs.values, columns=['corr'])\n",
    "fscore_corr = pd.concat([f, score_corr], axis=1).sort_values(by='corr', ascending=False).reset_index(drop=True)\n",
    "fscore_corr.head()\n",
    "\n",
    "\n",
    "# # >=0.01\n",
    "# features_top = {}\n",
    "# features_top['corr'] = correlations_target_abs[correlations_target_abs>=0.01]\n",
    "# features_top['corr'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 9)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>corr</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lgb</th>\n",
       "      <th>corr_rank</th>\n",
       "      <th>rf_rank</th>\n",
       "      <th>xgb_rank</th>\n",
       "      <th>lgb_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>外部评分</td>\n",
       "      <td>0.131480</td>\n",
       "      <td>0.069753</td>\n",
       "      <td>0.012082</td>\n",
       "      <td>2253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>出生日期距申请日期天数</td>\n",
       "      <td>0.103142</td>\n",
       "      <td>0.045533</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>3073</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>客户居住地评分2</td>\n",
       "      <td>0.078824</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.011659</td>\n",
       "      <td>326</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>客户居住地评分1</td>\n",
       "      <td>0.076496</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.008773</td>\n",
       "      <td>208</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>最近一次换手机号码距申请日天数</td>\n",
       "      <td>0.074596</td>\n",
       "      <td>0.019166</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>2442</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature      corr        rf       xgb   lgb  corr_rank  rf_rank  \\\n",
       "0             外部评分  0.131480  0.069753  0.012082  2253        1.0      1.0   \n",
       "1      出生日期距申请日期天数  0.103142  0.045533  0.007693  3073        2.0      2.0   \n",
       "2         客户居住地评分2  0.078824  0.009034  0.011659   326        3.0     32.0   \n",
       "3         客户居住地评分1  0.076496  0.007921  0.008773   208        4.0     37.0   \n",
       "4  最近一次换手机号码距申请日天数  0.074596  0.019166  0.005011  2442        5.0     11.0   \n",
       "\n",
       "   xgb_rank  lgb_rank  \n",
       "0       4.0       8.0  \n",
       "1      11.0       2.0  \n",
       "2       5.0     106.0  \n",
       "3       8.0     133.0  \n",
       "4      34.0       7.0  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Merge important\n",
    "\n",
    "fscore = pd.merge(fscore_corr, fscore_rf, on='feature')\n",
    "fscore = pd.merge(fscore, fscore_xgb, on='feature')\n",
    "fscore = pd.merge(fscore, fscore_lgb, on='feature')\n",
    "# Add rank\n",
    "frank = fscore.rank(numeric_only=True, method='min', ascending=False)\n",
    "fscore = pd.merge(fscore, frank, left_index=True, right_index=True, suffixes=['', '_rank'])\n",
    "\n",
    "fscore.shape\n",
    "fscore.head()\n",
    "fscore.to_csv('./model/f_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Corr '"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lgb</th>\n",
       "      <th>rf_xgb</th>\n",
       "      <th>rf_lgb</th>\n",
       "      <th>xgb_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Intersection</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              corr    rf   xgb   lgb  rf_xgb  rf_lgb  xgb_lgb\n",
       "Intersection   1.0  0.82  0.79  0.79    0.83    0.92     0.86"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Describe '"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corr</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>4.020000e+02</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.865047e-02</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>303.960396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.889350e-02</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>538.189261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.216878e-15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.952374e-03</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.133761e-02</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>67.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>2.872666e-02</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>352.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.314799e-01</td>\n",
       "      <td>0.069753</td>\n",
       "      <td>0.018646</td>\n",
       "      <td>3160.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               corr          rf         xgb          lgb\n",
       "count  4.020000e+02  404.000000  404.000000   404.000000\n",
       "mean   1.865047e-02    0.002475    0.002475   303.960396\n",
       "std    1.889350e-02    0.005980    0.002375   538.189261\n",
       "min    1.216878e-15    0.000000    0.000000     0.000000\n",
       "25%    3.952374e-03    0.000002    0.000000     1.000000\n",
       "50%    1.133761e-02    0.000490    0.002663    67.500000\n",
       "75%    2.872666e-02    0.001745    0.003452   352.500000\n",
       "max    1.314799e-01    0.069753    0.018646  3160.000000"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Importance '"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'corr'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00811653, 0.008091  , 0.0078265 , 0.00772824, 0.00771769])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'rf'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00024913, 0.00024818, 0.00020295, 0.00019876, 0.00022517])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'xgb'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.00233615, 0.00232134, 0.00234626, 0.00233459, 0.00229456],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'lgb'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([27, 29, 30, 31])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Intersection\n",
    "\n",
    "n = len(fscore)\n",
    "m = round(n * 0.6)\n",
    "m\n",
    "\n",
    "top_f = {}\n",
    "inter_cnt = {}\n",
    "for k in 'corr', 'rf', 'xgb', 'lgb':\n",
    "    top_f[k] = set(fscore.loc[fscore[f'{k}_rank']<=m, 'feature'])\n",
    "    inter_cnt[k] = round(len(top_f['corr'].intersection(top_f[k]))/m, 2)\n",
    "    \n",
    "inter_cnt['rf_xgb'] = round(len(top_f['rf'].intersection(top_f['xgb']))/m, 2)\n",
    "inter_cnt['rf_lgb'] = round(len(top_f['rf'].intersection(top_f['lgb']))/m, 2)\n",
    "inter_cnt['xgb_lgb'] = round(len(top_f['xgb'].intersection(top_f['lgb']))/m, 2)\n",
    "\n",
    "''' Corr '''\n",
    "pd.DataFrame(inter_cnt, index=['Intersection'])\n",
    "\n",
    "''' Describe '''\n",
    "fscore[['corr', 'rf', 'xgb', 'lgb']].describe()\n",
    "\n",
    "''' Importance ''' \n",
    "for k in 'corr', 'rf', 'xgb', 'lgb':\n",
    "    k\n",
    "    fscore.loc[(fscore[f'{k}_rank']>(m-3)) & (fscore[f'{k}_rank']<(m+3)), k].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf_xgb</th>\n",
       "      <th>rf_lgb</th>\n",
       "      <th>xgb_lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Intersection</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rf_xgb  rf_lgb  xgb_lgb\n",
       "Intersection    0.83    0.92     0.86"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Save Top Features\n",
    "\n",
    "m\n",
    "\n",
    "feats = {}\n",
    "for k in 'rf', 'xgb', 'lgb':\n",
    "    feats[k] = fscore.loc[fscore[f'{k}_rank']<=m, 'feature'].to_list()\n",
    "\n",
    "np.save('./model/base_features.npy', feats)\n",
    "\n",
    "# Check\n",
    "inter_cnt = {}\n",
    "inter_cnt['rf_xgb'] = round(len(set(feats['rf']).intersection(set(feats['xgb'])))/m, 2)\n",
    "inter_cnt['rf_lgb'] = round(len(set(feats['rf']).intersection(set(feats['lgb'])))/m, 2)\n",
    "inter_cnt['xgb_lgb'] = round(len(set(feats['xgb']).intersection(set(feats['lgb'])))/m, 2)\n",
    "pd.DataFrame(inter_cnt, index=['Intersection'])\n",
    "\n",
    "# f = np.load('./model/base_features.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Include? '"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Diff '"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'商品类别_17mean',\n",
       " '商品类别_17sum',\n",
       " '行业_1sum',\n",
       " '行业_3sum',\n",
       " '贷款用途_14sum',\n",
       " '贷款用途_20sum',\n",
       " '贷款用途_21sum'}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Check Corr\n",
    "\n",
    "corr_top = 200\n",
    "\n",
    "top = {}\n",
    "top['corr'] = set(fscore.loc[fscore['corr_rank']<=corr_top, 'feature'].to_list())\n",
    "top['all'] = set(feats['rf'] + feats['xgb'] + feats['lgb'])\n",
    "len(top['corr'])\n",
    "len(top['all'])\n",
    "''' Include? '''\n",
    "\n",
    "''' Diff '''\n",
    "diff = top['corr'].difference(top['all'])\n",
    "len(diff)\n",
    "diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
