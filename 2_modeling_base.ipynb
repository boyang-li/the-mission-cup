{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Meng/opt/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats as spstats\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def get_time():\n",
    "    now = datetime.datetime.now().strftime(\"%m-%d %H:%M\")\n",
    "    print(now)\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Grid Search\n",
    "\n",
    "scale_pos_weight = 119/21\n",
    "cv = 5\n",
    "\n",
    "param_general = {\n",
    "    'n_iter' : 50,\n",
    "    'cv' : cv, \n",
    "    'scoring' : 'roc_auc', \n",
    "    'n_jobs' : -1, \n",
    "    'random_state' : 123, \n",
    "    'verbose' : 1}\n",
    "\n",
    "# RF\n",
    "param_dist_rf = {\n",
    "    # Shape\n",
    "    'n_estimators' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_samples_split' : range(50, 100, 10),\n",
    "    'min_samples_leaf' : range(50, 100, 10),\n",
    "    # Sample\n",
    "    'class_weight' : ['balanced', None],\n",
    "    'max_features' : ['sqrt', 'log2'],\n",
    "    # Objective\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_dist_xgb = {\n",
    "    # Shape\n",
    "    'n_estimators' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'scale_pos_weight' : [scale_pos_weight, 1],\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bytree' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bylevel' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'eta' : np.linspace(0.01, 0.2, 20), # Learning_rate\n",
    "    'alpha' : np.linspace(0, 1, 10),\n",
    "    'lambda' : range(0, 50, 5),\n",
    "    'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_dist_lgb = {\n",
    "    # Shape\n",
    "    'num_boost_round' : range(50, 500, 50),\n",
    "#     'num_boost_round' : range(50, 100, 10),\n",
    "    'num_leaves' : range(2**3, 2**10, 100),\n",
    "    'min_data_in_leaf' : range(50, 100, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'is_unbalance' : [True, False],\n",
    "    'bagging_freq': range(2, 10), # >0 enable bagging_fraction\n",
    "    'bagging_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'feature_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'learning_rate':np.linspace(0.01, 0.2, 20),    \n",
    "    'lambda_l1': np.linspace(0, 1, 10),\n",
    "    'lambda_l2': range(0, 50, 5),\n",
    "    'cat_smooth': range(1, 40, 5)\n",
    "#     'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "param_dist_lr = {\n",
    "    # Shape\n",
    "    'max_iter' : range(50, 500, 50),\n",
    "    # Sample\n",
    "    'class_weight' : [scale_pos_weight, 1],\n",
    "    # Algo\n",
    "    'solver' : ['sag', 'lbfgs', 'newton-cg'],\n",
    "    'C': [0.001, 0.01, 0.1] # 1/λ\n",
    "}\n",
    "\n",
    "##########\n",
    "\n",
    "# RF\n",
    "param_fixed_rf = {\n",
    "    'n_jobs' : -1,\n",
    "    'oob_score' : True,\n",
    "    'random_state':123,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_fixed_xgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'seed' : 123,\n",
    "    'silent' : 1,\n",
    "    'verbose_eval':0\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_fixed_lgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'metric' : 'auc',\n",
    "    'random_state' : 123,\n",
    "    'bagging_seed':123,\n",
    "    'feature_fraction_seed':123,\n",
    "    'verbose_eval' : 0\n",
    "}\n",
    "\n",
    "# LR\n",
    "param_fixed_lr = {\n",
    "    'n_jobs' : -1,\n",
    "    'random_state' : 123,\n",
    "    'verbose' : 0     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' *** With nona *** '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Load '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Merge '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Split '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 811)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' *** With na *** '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Load '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Merge '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 812)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Split '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000, 811)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(140000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################  Load Features\n",
    "\n",
    "''' *** With nona *** '''\n",
    "\n",
    "''' Load '''\n",
    "Xid = pd.read_csv('./tmp/train_d1234_nona.csv', header=0, index_col=0)\n",
    "Xid.shape\n",
    "\n",
    "yid = pd.read_csv('./data/train_label.csv', header=0, index_col=0)\n",
    "yid.shape\n",
    "\n",
    "''' Merge '''\n",
    "xy = pd.merge(Xid, yid, on=uid, how='inner')\n",
    "xy.drop(uid, axis=1, inplace=True)\n",
    "xy.shape\n",
    "\n",
    "''' Split '''\n",
    "# X, y\n",
    "X = xy.copy()\n",
    "y = X.pop(target)\n",
    "X.shape\n",
    "y.shape\n",
    "\n",
    "''' *** With na *** '''\n",
    "\n",
    "''' Load '''\n",
    "Xid1 = pd.read_csv('./tmp/train_d1234_na.csv', header=0, index_col=0)\n",
    "Xid1.shape\n",
    "\n",
    "''' Merge '''\n",
    "xy1 = pd.merge(Xid1, yid, on=uid, how='inner')\n",
    "xy1.drop(uid, axis=1, inplace=True)\n",
    "xy1.shape\n",
    "\n",
    "''' Split '''\n",
    "# X, y\n",
    "X1 = xy1.copy()\n",
    "y1 = X1.pop(target)\n",
    "X1.shape\n",
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, bagging_seed=123,\n",
       "               boosting_type='gbdt', cat_smooth=16, class_weight=None,\n",
       "               colsample_bytree=1.0, feature_fraction=0.9,\n",
       "               feature_fraction_seed=123, importance_type='split',\n",
       "               is_unbalance=True, lambda_l1=0.8888888888888888, lambda_l2=25,\n",
       "               learning_rate=0.02, max_depth=-1, metric='auc',\n",
       "               min_child_samples=20, min_child_weight=2, min_data_in_leaf=90,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "               num_boost_round=400, num_leaves=308, objective=None,\n",
       "               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=0.8, ...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>lgb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>信用额度</td>\n",
       "      <td>3291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>贷款年金</td>\n",
       "      <td>3097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>身份认证日期距申请日期天数</td>\n",
       "      <td>2762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>最近一次换手机号码距申请日天数</td>\n",
       "      <td>2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>外部评分</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature   lgb\n",
       "0             信用额度  3291\n",
       "1             贷款年金  3097\n",
       "2    身份认证日期距申请日期天数  2762\n",
       "3  最近一次换手机号码距申请日天数  2367\n",
       "4             外部评分  2352"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LGB with Na ###\n",
    "\n",
    "# LGB\n",
    "best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lgb}\n",
    "LGB = LGBMClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "LGB.fit(X1, y1)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(LGB.feature_importances_, columns=['lgb'])\n",
    "fscore_lgb = pd.concat([f, score], axis=1).sort_values(by='lgb', ascending=False).reset_index(drop=True)\n",
    "fscore_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                       criterion='entropy', max_depth=9, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=50,\n",
       "                       min_samples_split=50, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=400, n_jobs=-1, oob_score=True,\n",
       "                       random_state=123, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>外部评分</td>\n",
       "      <td>0.052359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>工作日期距申请日期天数</td>\n",
       "      <td>0.036302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>出生日期距申请日期天数</td>\n",
       "      <td>0.026522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>最近一次换手机号码距申请日天数</td>\n",
       "      <td>0.017826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>教育程度_1</td>\n",
       "      <td>0.015429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature        rf\n",
       "0             外部评分  0.052359\n",
       "1      工作日期距申请日期天数  0.036302\n",
       "2      出生日期距申请日期天数  0.026522\n",
       "3  最近一次换手机号码距申请日天数  0.017826\n",
       "4           教育程度_1  0.015429"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################ Important Features ################\n",
    "\n",
    "######## Base Models ########\n",
    "\n",
    "### RF ###\n",
    "\n",
    "best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_rf}\n",
    "RF = RandomForestClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "RF.fit(X, y)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(RF.feature_importances_, columns=['rf'])\n",
    "fscore_rf = pd.concat([f, score], axis=1).sort_values(by='rf', ascending=False).reset_index(drop=True)\n",
    "fscore_rf.head()\n",
    "\n",
    "### XGB ###\n",
    "\n",
    "# XGB\n",
    "best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_xgb}\n",
    "XGB = XGBClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "XGB.fit(X, y)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(XGB.feature_importances_, columns=['xgb'])\n",
    "fscore_xgb = pd.concat([f, score], axis=1).sort_values(by='xgb', ascending=False).reset_index(drop=True)\n",
    "fscore_xgb.head()\n",
    "\n",
    "### LGB ###\n",
    "\n",
    "# LGB\n",
    "best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "model_params = {**best_params_load, **param_fixed_lgb}\n",
    "LGB = LGBMClassifier(**model_params)\n",
    "\n",
    "# Train\n",
    "LGB.fit(X, y)\n",
    "\n",
    "# Importance\n",
    "f = pd.DataFrame(X.columns, columns=['feature'])\n",
    "score = pd.DataFrame(LGB.feature_importances_, columns=['lgb'])\n",
    "fscore_lgb = pd.concat([f, score], axis=1).sort_values(by='lgb', ascending=False).reset_index(drop=True)\n",
    "fscore_lgb.head()\n",
    "\n",
    "######## correlations ########\n",
    "\n",
    "correlations = xy.corr()\n",
    "\n",
    "# Save\n",
    "correlations.apply(abs).to_csv('./ana/0_correlations_abs.csv')\n",
    "correlations.to_csv('./ana/0_correlations.csv')\n",
    "\n",
    "# Abs\n",
    "correlations_target_abs = correlations.loc[correlations.index != target, target].apply(abs).sort_values(ascending=False)\n",
    "\n",
    "f = pd.DataFrame(correlations_target_abs.index, columns=['feature'])\n",
    "score_corr = pd.DataFrame(correlations_target_abs.values, columns=['corr'])\n",
    "fscore_corr = pd.concat([f, score_corr], axis=1).sort_values(by='corr', ascending=False).reset_index(drop=True)\n",
    "fscore_corr.head()\n",
    "\n",
    "######## Merge ########\n",
    "\n",
    "fscore = pd.merge(fscore_corr, fscore_rf, on='feature')\n",
    "fscore = pd.merge(fscore, fscore_xgb, on='feature')\n",
    "fscore = pd.merge(fscore, fscore_lgb, on='feature')\n",
    "\n",
    "# Add rank\n",
    "frank = fscore.rank(numeric_only=True, method='min', ascending=False)\n",
    "fscore.fillna(0, inplace=True)\n",
    "fscore = pd.merge(fscore, frank, left_index=True, right_index=True, suffixes=['', '_rank'])\n",
    "fscore['rank'] = fscore['corr_rank'] + fscore['rf_rank'] + fscore['xgb_rank'] + fscore['lgb_rank']\n",
    "fscore.sort_values(by='rank', inplace=True)\n",
    "\n",
    "fscore.shape\n",
    "fscore.head()\n",
    "fscore.to_csv('./model/f_score.csv')\n",
    "\n",
    "''' Describe '''\n",
    "fscore[['corr', 'rf', 'xgb', 'lgb', 'rank']].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Intersection by Score ########\n",
    "\n",
    "# By score\n",
    "# th_imp = {'corr':0.01, 'rf':0.002, 'xgb':0.003, 'lgb':5} # 404\n",
    "# th_imp = {'corr':0.01, 'rf':0.0005, 'xgb':0.0015, 'lgb':5} # 801, 518\t318\t397\n",
    "th_imp = {'corr':0.01, 'rf':0.002, 'xgb':0, 'lgb':0} # 518\t318\t397\n",
    "# th_imp = {'corr':0, 'rf':0, 'xgb':0, 'lgb':0} \n",
    "\n",
    "top_f = {}\n",
    "cnt_f = {}\n",
    "inter_cnt = {}\n",
    "for k in 'corr', 'rf', 'xgb', 'lgb':\n",
    "    # top\n",
    "    t = fscore.loc[fscore[f'{k}']>=th_imp[k], 'feature']\n",
    "    top_f[k] = set(t) # set\n",
    "    # len\n",
    "    cnt_f[f'cnt_{k}'] = len(t)\n",
    "    # intersection with Corr\n",
    "    inter_cnt[f'corr_{k}'] = round(len(top_f['corr'].intersection(top_f[k]))/len(top_f['corr']), 2)\n",
    "\n",
    "# Intersection\n",
    "inter_cnt['rf_xgb'] = round(len(top_f['rf'].intersection(top_f['xgb']))/len(top_f['rf']), 2)\n",
    "inter_cnt['xgb_rf'] = round(len(top_f['rf'].intersection(top_f['xgb']))/len(top_f['xgb']), 2)\n",
    "inter_cnt['rf_lgb'] = round(len(top_f['rf'].intersection(top_f['lgb']))/len(top_f['rf']), 2)\n",
    "inter_cnt['lgb_rf'] = round(len(top_f['rf'].intersection(top_f['lgb']))/len(top_f['lgb']), 2)\n",
    "inter_cnt['xgb_lgb'] = round(len(top_f['xgb'].intersection(top_f['lgb']))/len(top_f['xgb']), 2)\n",
    "inter_cnt['lgb_xgb'] = round(len(top_f['xgb'].intersection(top_f['lgb']))/len(top_f['lgb']), 2)\n",
    "\n",
    "''' Corr '''\n",
    "pd.DataFrame(cnt_f, index=['Count'])\n",
    "pd.DataFrame(inter_cnt, index=['Intersection'])\n",
    "\n",
    "''' all VS corr '''\n",
    "top = {}\n",
    "# top['all'] = top_f['rf'].union(top_f['xgb']).union(top_f['lgb'])\n",
    "top['all'] = top_f['rf'].union(top_f['xgb'])\n",
    "diff = top_f['corr'].difference(top['all'])\n",
    "len(diff)\n",
    "# diff\n",
    "\n",
    "### Save\n",
    "np.save('./model/base_features.npy', top_f)\n",
    "\n",
    "# # + diff\n",
    "# ''' top_f_final ''' \n",
    "# top_f_final = {} # 入模特征列表\n",
    "# for k in 'rf', 'xgb', 'lgb':\n",
    "#     top_f_final[k] = top_f[k].union(diff) # 保存特征列表\n",
    "#     len(top_f_final[k])\n",
    "\n",
    "# ### Save\n",
    "# np.save('./model/base_features.npy', top_f_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Polynomial\n",
    "\n",
    "m = 50 # 交集\n",
    "n = 10 # 合集\n",
    "\n",
    "top_f_inters = set(fscore.loc[(fscore['corr_rank'] <= m) & \n",
    "                          (fscore['rf_rank'] <= m) & \n",
    "                          (fscore['xgb_rank'] <= m) & \n",
    "                          (fscore['lgb_rank'] <= m), 'feature'])\n",
    "len(top_f_inters)\n",
    "top_f_union = set(fscore.loc[(fscore['corr_rank'] <= n) | \n",
    "                          (fscore['rf_rank'] <= n) | \n",
    "                          (fscore['xgb_rank'] <= n) | \n",
    "                          (fscore['lgb_rank'] <= n), 'feature'])\n",
    "len(top_f_union)\n",
    "top_poly = top_f_inters.union(top_f_union)\n",
    "len(top_poly)\n",
    "top_poly\n",
    "\n",
    "np.save('./tmp/0_feats_poly.npy', top_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=True, random_state=123, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9852"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 51.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 68.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=-1, oob_scor...\n",
       "                   param_distributions={'class_weight': ['balanced', None],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(3, 10),\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': range(50, 100, 10),\n",
       "                                        'min_samples_split': range(50, 100, 10),\n",
       "                                        'n_estimators': range(50, 500, 50)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7002853321328532"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:01\n"
     ]
    }
   ],
   "source": [
    "# ############## RF\n",
    "\n",
    "# get_time()\n",
    "# ''' Baseline '''\n",
    "# baseline = RandomForestClassifier(**param_fixed_rf)\n",
    "# baseline.fit(X, y)\n",
    "# pred_baseline = baseline.predict_proba(X)\n",
    "# ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "# get_time()\n",
    "# ''' Best '''\n",
    "# grid = RandomizedSearchCV(RandomForestClassifier(**param_fixed_rf), param_dist_rf, **param_general)\n",
    "# grid.fit(X, y)\n",
    "# grid.best_score_\n",
    "# best_params = grid.best_params_\n",
    "# np.save('./model/base_rf.npy', best_params)\n",
    "# get_time()\n",
    "\n",
    "# # ''' Test Clone Model '''\n",
    "# # model1 = grid.best_estimator_\n",
    "# # model1.fit(X, y)\n",
    "# # ks_score(y, model1.predict_proba(X)[:,1])\n",
    "# # \n",
    "# # ''' Test Save Params '''\n",
    "# # best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "# # model2_params = {**best_params_load, **param_fixed_rf}\n",
    "# # model2 = RandomForestClassifier(**model2_params)\n",
    "# # model2.fit(X, y)\n",
    "# # ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=123, silent=1,\n",
       "              subsample=1, verbose_eval=0, verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3422"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 160.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 220.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1,\n",
       "                                           eval_metric='auc', gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=-1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_...\n",
       "                                        'eta': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ]),\n",
       "                                        'lambda': range(0, 50, 5),\n",
       "                                        'max_depth': range(3, 10),\n",
       "                                        'min_child_weight': range(1, 9),\n",
       "                                        'n_estimatores': range(50, 500, 50),\n",
       "                                        'scale_pos_weight': [5.666666666666667,\n",
       "                                                             1],\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7251946138455383"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 15:55\n",
      "10-20 15:55\n"
     ]
    }
   ],
   "source": [
    "# ############## XGB\n",
    "\n",
    "# get_time()\n",
    "# ''' Baseline '''\n",
    "# baseline = XGBClassifier(**param_fixed_xgb)\n",
    "# baseline.fit(X, y)\n",
    "# pred_baseline = baseline.predict_proba(X)\n",
    "# ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "# get_time()\n",
    "# ''' Best '''\n",
    "# grid = RandomizedSearchCV(XGBClassifier(**param_fixed_xgb), param_dist_xgb, **param_general)\n",
    "# grid.fit(X, y)\n",
    "# grid.best_score_\n",
    "# best_params = grid.best_params_\n",
    "# np.save('./model/base_xgb.npy', best_params)\n",
    "# get_time()\n",
    "# get_time()\n",
    "\n",
    "# # ''' Test Clone Model '''\n",
    "# # model1 = grid.best_estimator_\n",
    "# # model1.fit(X, y)\n",
    "# # ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# # ''' Test Save Params '''\n",
    "# # best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "# # model2_params = {**best_params_load, **param_fixed_xgb}\n",
    "# # model2 = XGBClassifier(**model2_params)\n",
    "# # model2.fit(X, y)\n",
    "# # ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_seed=123, boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=1.0, feature_fraction_seed=123,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               metric='auc', min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0, verbose_eval=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4274"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 69.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=LGBMClassifier(bagging_seed=123,\n",
       "                                            boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            feature_fraction_seed=123,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            metric='auc', min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leav...\n",
       "                                        'learning_rate': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ]),\n",
       "                                        'min_child_weight': range(1, 9),\n",
       "                                        'min_data_in_leaf': range(50, 100, 10),\n",
       "                                        'num_boost_round': range(50, 500, 50),\n",
       "                                        'num_leaves': range(8, 1024, 100),\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7294587094837935"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:13\n"
     ]
    }
   ],
   "source": [
    "# ############## LGB\n",
    "\n",
    "# get_time()\n",
    "# ''' Baseline '''\n",
    "# baseline = LGBMClassifier(**param_fixed_lgb)\n",
    "# baseline.fit(X, y)\n",
    "# pred_baseline = baseline.predict_proba(X) #, num_iteration=baseline.best_iteration_)\n",
    "# ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "# get_time()\n",
    "# ''' Best '''\n",
    "# grid = RandomizedSearchCV(LGBMClassifier(**param_fixed_lgb), param_dist_lgb, **param_general)\n",
    "# grid.fit(X, y)\n",
    "# grid.best_score_\n",
    "# best_params = grid.best_params_\n",
    "# np.save('./model/base_lgb.npy', best_params)\n",
    "# get_time()\n",
    "\n",
    "# # ''' Test Clone Model '''\n",
    "# # model1 = grid.best_estimator_\n",
    "# # model1.fit(X, y)\n",
    "# # ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# # ''' Test Save Params '''\n",
    "# # best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "# # model2_params = {**best_params_load, **param_fixed_lgb}\n",
    "# # model2 = LGBMClassifier(**model2_params)\n",
    "# # model2.fit(X, y)\n",
    "# # ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 7)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ######## Tune Meta\n",
    "\n",
    "# X_meta = pd.read_csv('./tmp/meta_X.csv', header=0, index_col=0).values\n",
    "# poly = PolynomialFeatures(3, interaction_only=True)\n",
    "# X_meta = poly.fit_transform(X_meta)[:,1:]\n",
    "# X_meta.shape\n",
    "\n",
    "# y_meta = y.values\n",
    "\n",
    "# # LR\n",
    "# best_params_load = np.load('./model/base_lr.npy', allow_pickle=True).item()\n",
    "# model_params = {**best_params_load, **param_fixed_lr}\n",
    "# LR = LogisticRegression(**model_params)\n",
    "\n",
    "# # Tune\n",
    "#         ks = []\n",
    "#         meta_model = LR\n",
    "        \n",
    "#         kfold = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "#         j = 0\n",
    "#         meta_models_ = []\n",
    "#         for train_index, valid_index in kfold.split(X_meta, y_meta):\n",
    "#             instance = clone(meta_model)\n",
    "#             meta_models_.append(instance)\n",
    "#             instance.fit(X_meta[train_index],  y_meta[train_index])\n",
    "#             y_pred = instance.predict_proba(X_meta[valid_index])[:,1]\n",
    "#             ks.append(ks_score(y_meta[valid_index], y_pred))\n",
    "#             print(ks)\n",
    "#             j += 1\n",
    "#         pd.DataFrame(ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140000, 6)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=123, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3507"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   20.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                dual=False, fit_intercept=True,\n",
       "                                                intercept_scaling=1,\n",
       "                                                l1_ratio=None, max_iter=100,\n",
       "                                                multi_class='warn', n_jobs=-1,\n",
       "                                                penalty='l2', random_state=123,\n",
       "                                                solver='warn', tol=0.0001,\n",
       "                                                verbose=0, warm_start=False),\n",
       "                   iid='warn', n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'C': [0.001, 0.01, 0.1],\n",
       "                                        'class_weight': [5.666666666666667, 1],\n",
       "                                        'max_iter': range(50, 500, 50),\n",
       "                                        'solver': ['sag', 'lbfgs',\n",
       "                                                   'newton-cg']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.735806162464986"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Test Clone Model '"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=1, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3503"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "' Test Save Params '"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=1, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=-1, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3503"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ############## LR\n",
    "\n",
    "# X_meta = pd.read_csv('./tmp/meta_X.csv', header=0, index_col=0).values\n",
    "# poly = PolynomialFeatures(2, interaction_only=True, include_bias=False)\n",
    "# X_meta = poly.fit_transform(X_meta)\n",
    "# X_meta.shape\n",
    "# y_meta = y.values\n",
    "\n",
    "# ''' Baseline '''\n",
    "# baseline = LogisticRegression(**param_fixed_lr)\n",
    "# baseline.fit(X_meta, y)\n",
    "# pred_baseline = baseline.predict_proba(X_meta)\n",
    "# ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "# ''' Best '''\n",
    "# grid = RandomizedSearchCV(LogisticRegression(**param_fixed_lr), param_dist_lr, **param_general)\n",
    "# grid.fit(X_meta, y)\n",
    "# grid.best_score_\n",
    "# best_params = grid.best_params_\n",
    "# np.save('./model/base_lr.npy', best_params)\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X_meta, y)\n",
    "# ks_score(y, model1.predict_proba(X_meta)[:,1])\n",
    "\n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_lr.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_lr}\n",
    "# model2 = LogisticRegression(**model2_params)\n",
    "# model2.fit(X_meta, y)\n",
    "# ks_score(y, model2.predict_proba(X_meta)[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
