{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity='all'\n",
    "%matplotlib inline\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin, clone\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = '标签'\n",
    "uid = '申请编号'\n",
    "\n",
    "def get_time():\n",
    "    now = datetime.datetime.now().strftime(\"%m-%d %H:%M\")\n",
    "    print(now)\n",
    "\n",
    "def calc_auc(y_test, y_proba):\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_proba), 3)\n",
    "    return auc\n",
    "\n",
    "def ks_score(y_test, y_proba):\n",
    "    scale = 4\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, y_proba, pos_label=1)\n",
    "    KS = round(max(list(tpr-fpr)), scale)\n",
    "    return KS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "140000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############## Load\n",
    "\n",
    "# X = pd.read_csv('./tmp/1_X.csv', header=0, index_col=0)\n",
    "# X.shape\n",
    "# X.head()\n",
    "\n",
    "# y = pd.read_csv('./tmp/1_y.csv', header=0, index_col=0)\n",
    "# y.shape\n",
    "# y.head()\n",
    "\n",
    "X = pd.read_csv('./tmp/train_d12_d3_dum.csv', header=0, index_col=0).drop(uid, axis=1).values\n",
    "# X = pd.read_csv('./tmp/1_X.csv', header=0, index_col=0).values\n",
    "len(X)\n",
    "len(X[0])\n",
    "\n",
    "y = pd.read_csv('./tmp/1_y.csv', header=0, index_col=0)['0'].values\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Grid Search\n",
    "\n",
    "scale_pos_weight = 119/21\n",
    "\n",
    "param_general = {\n",
    "#     'n_iter' : 100,\n",
    "#     'cv' : 5, \n",
    "    'n_iter' : 50,\n",
    "    'cv' : 5, \n",
    "    'scoring' : 'roc_auc', \n",
    "    'n_jobs' : -1, \n",
    "    'random_state' : 123, \n",
    "    'verbose' : 1}\n",
    "\n",
    "# RF\n",
    "param_dist_rf = {\n",
    "    # Shape\n",
    "    'n_estimators' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_samples_split' : range(50, 100, 10),\n",
    "    'min_samples_leaf' : range(50, 100, 10),\n",
    "    # Sample\n",
    "    'class_weight' : ['balanced', None],\n",
    "    'max_features' : ['sqrt', 'log2'],\n",
    "    # Objective\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_dist_xgb = {\n",
    "    # Shape\n",
    "    'n_estimatores' : range(50, 500, 50),\n",
    "#     'n_estimators' : range(5, 10),\n",
    "    'max_depth' : range(3, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'scale_pos_weight' : [scale_pos_weight, 1],\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bytree' : np.linspace(0.5, 0.9, 5),\n",
    "    'colsample_bylevel' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'eta' : np.linspace(0.01, 0.2, 20), # Learning_rate\n",
    "    'alpha' : np.linspace(0, 1, 10),\n",
    "    'lambda' : range(0, 50, 5),\n",
    "    'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_dist_lgb = {\n",
    "    # Shape\n",
    "    'num_boost_round' : range(50, 500, 50),\n",
    "#     'num_boost_round' : range(50, 100, 10),\n",
    "    'num_leaves' : range(2**3, 2**10, 100),\n",
    "    'min_data_in_leaf' : range(50, 100, 10),\n",
    "    'min_child_weight' : range(1, 9, 1), # 最小叶子节点样本权重和\n",
    "    # Sample\n",
    "    'is_unbalance' : [True, False],\n",
    "    'bagging_freq': range(2, 10), # >0 enable bagging_fraction\n",
    "    'bagging_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'feature_fraction': np.linspace(0.5, 0.9, 5),\n",
    "    'subsample' : np.linspace(0.5, 0.9, 5),\n",
    "    # Algo\n",
    "    'learning_rate':np.linspace(0.01, 0.2, 20),    \n",
    "    'lambda_l1': np.linspace(0, 1, 10),\n",
    "    'lambda_l2': range(0, 50, 5),\n",
    "    'cat_smooth': range(1, 40, 5)\n",
    "#     'early_stopping_rounds' : range(10, 20, 5)\n",
    "}\n",
    "\n",
    "##########\n",
    "\n",
    "# RF\n",
    "param_fixed_rf = {\n",
    "    'n_jobs' : -1,\n",
    "    'oob_score' : True,\n",
    "    'random_state':123,\n",
    "    'verbose':0\n",
    "}\n",
    "\n",
    "# XGB\n",
    "param_fixed_xgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'eval_metric': 'auc',\n",
    "    'seed' : 123,\n",
    "    'silent' : 1,\n",
    "    'verbose_eval':0\n",
    "}\n",
    "\n",
    "# LGB\n",
    "param_fixed_lgb = {\n",
    "    'n_jobs' : -1,\n",
    "    'metric' : 'auc',\n",
    "    'bagging_seed':123,\n",
    "    'feature_fraction_seed':123,\n",
    "    'verbose_eval' : 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "                       oob_score=True, random_state=123, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9852"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 09:51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 51.0min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 68.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=-1, oob_scor...\n",
       "                   param_distributions={'class_weight': ['balanced', None],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(3, 10),\n",
       "                                        'max_features': ['sqrt', 'log2'],\n",
       "                                        'min_samples_leaf': range(50, 100, 10),\n",
       "                                        'min_samples_split': range(50, 100, 10),\n",
       "                                        'n_estimators': range(50, 500, 50)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7002853321328532"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:01\n"
     ]
    }
   ],
   "source": [
    "############## RF\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = RandomForestClassifier(**param_fixed_rf)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(RandomForestClassifier(**param_fixed_rf), param_dist_rf, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_rf.npy', best_params)\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "# \n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_rf.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_rf}\n",
    "# model2 = RandomForestClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=123, silent=1,\n",
       "              subsample=1, verbose_eval=0, verbosity=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.3422"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 160.9min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 220.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1,\n",
       "                                           eval_metric='auc', gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=3, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=-1, nthread=None,\n",
       "                                           objective='binary:logistic',\n",
       "                                           random_...\n",
       "                                        'eta': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ]),\n",
       "                                        'lambda': range(0, 50, 5),\n",
       "                                        'max_depth': range(3, 10),\n",
       "                                        'min_child_weight': range(1, 9),\n",
       "                                        'n_estimatores': range(50, 500, 50),\n",
       "                                        'scale_pos_weight': [5.666666666666667,\n",
       "                                                             1],\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7251946138455383"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 15:55\n",
      "10-20 15:55\n"
     ]
    }
   ],
   "source": [
    "############## XGB\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = XGBClassifier(**param_fixed_xgb)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(XGBClassifier(**param_fixed_xgb), param_dist_xgb, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_xgb.npy', best_params)\n",
    "get_time()\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_xgb.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_xgb}\n",
    "# model2 = XGBClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Baseline '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_seed=123, boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=1.0, feature_fraction_seed=123,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               metric='auc', min_child_samples=20, min_child_weight=0.001,\n",
       "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,\n",
       "               objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "               subsample_freq=0, verbose_eval=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.4274"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 11:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Best '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed: 69.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=LGBMClassifier(bagging_seed=123,\n",
       "                                            boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            feature_fraction_seed=123,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            metric='auc', min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leav...\n",
       "                                        'learning_rate': array([0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 , 0.11,\n",
       "       0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 ]),\n",
       "                                        'min_child_weight': range(1, 9),\n",
       "                                        'min_data_in_leaf': range(50, 100, 10),\n",
       "                                        'num_boost_round': range(50, 500, 50),\n",
       "                                        'num_leaves': range(8, 1024, 100),\n",
       "                                        'subsample': array([0.5, 0.6, 0.7, 0.8, 0.9])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=123, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7294587094837935"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-20 12:13\n"
     ]
    }
   ],
   "source": [
    "############## LGB\n",
    "\n",
    "get_time()\n",
    "''' Baseline '''\n",
    "baseline = LGBMClassifier(**param_fixed_lgb)\n",
    "baseline.fit(X, y)\n",
    "pred_baseline = baseline.predict_proba(X) #, num_iteration=baseline.best_iteration_)\n",
    "ks_score(y, pred_baseline[:,1])\n",
    "\n",
    "get_time()\n",
    "''' Best '''\n",
    "grid = RandomizedSearchCV(LGBMClassifier(**param_fixed_lgb), param_dist_lgb, **param_general)\n",
    "grid.fit(X, y)\n",
    "grid.best_score_\n",
    "best_params = grid.best_params_\n",
    "np.save('./model/base_lgb.npy', best_params)\n",
    "get_time()\n",
    "\n",
    "# ''' Test Clone Model '''\n",
    "# model1 = grid.best_estimator_\n",
    "# model1.fit(X, y)\n",
    "# ks_score(y, model1.predict_proba(X)[:,1])\n",
    "\n",
    "# ''' Test Save Params '''\n",
    "# best_params_load = np.load('./model/base_lgb.npy', allow_pickle=True).item()\n",
    "# model2_params = {**best_params_load, **param_fixed_lgb}\n",
    "# model2 = LGBMClassifier(**model2_params)\n",
    "# model2.fit(X, y)\n",
    "# ks_score(y, model2.predict_proba(X)[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
